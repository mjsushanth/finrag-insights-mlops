{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "295bffaa",
   "metadata": {},
   "source": [
    "## KPI extraction attempt: \n",
    "#### has (v1, 2, 3 - multiple attempts met with local GPU limitations.)\n",
    "#### Author : Joel Markapudi.\n",
    "\n",
    "Regex cant understand:\n",
    "- Temporal context (\"compared to prior year\")\n",
    "- Causal relationships (\"due to acquisition of...\")\n",
    "- Comparative statements (\"increased from X to Y\")\n",
    "- Multi-sentence KPI narratives\n",
    "- \"Sales rose to $2.3B\" (verb-first patterns), Table-extracted values without keywords, Abbreviated forms and industry-specific terminology.\n",
    "- Projected vs actual figures, Different reporting periods in same sentence, Parent company vs subsidiary metrics, Pro-forma vs GAAP measures\n",
    "\n",
    "```\n",
    "Type A: \"Revenue was $2.1B in 2018, $2.4B in 2019, and $2.8B in 2020\"\n",
    "Type B: \"Q1 through Q4 revenues were $500M, $520M, $510M, and $530M respectively\"  \n",
    "Type C: \"Operating margin improved from 12% to 15% while EBITDA grew from $200M to $280M\"\n",
    "Type D: \"2019: Revenue $2.4B (up 15%), Net Income $240M (up 18%), EPS $2.40 (up 20%)\"\n",
    "```\n",
    "\n",
    "#### Attempt1: leverage sota models, prod ready libs, 1M dataset which i prepped, try NER + finbert + small context model pattern.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11633208",
   "metadata": {},
   "source": [
    "```\n",
    "Input Sentence → [Stage 1: Context Classification] → [Stage 2: Entity Extraction] \n",
    "                            ↓                                    ↓\n",
    "                   (FinBERT/BART decides              (SpaCy + Patterns extract\n",
    "                    if KPI-bearing)                     actual values)\n",
    "                            ↓                                    ↓\n",
    "                        [Stage 3: Relation Linking] ←──────────┘\n",
    "                   (Connect entities to KPI types using rules + context)\n",
    "                            ↓\n",
    "                    [Stage 4: Validation & Normalization]\n",
    "                            ↓\n",
    "                      Structured KPI Record\n",
    "```\n",
    "\n",
    "\n",
    "1. Zero-shot classification using financial-tuned models\n",
    "2. SpaCy NER - Extracts standard entities: MONEY, PERCENT, DATE, ORG, CARDINAL\n",
    "3. Custom Financial Patterns ? maybe Regex patterns, and domain-specific formats: \"2.3B\", \"15bps\", \"3x EBITDA\"\n",
    "4. Dependency Parsing. SpaCy's dependency tree to find subject-object relationships. \n",
    "5. Relation Linking. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5912186",
   "metadata": {},
   "source": [
    "### Revised idea:\n",
    "\n",
    "1. One transformer model with good questions extracts 80% of what complex pipelines would get. The model already learned the hard parts (temporal relations, financial terminology, grammatical structures) during pre-training.\n",
    "\n",
    "```\n",
    "Input Sentences → [Quick Filter] → [FinBERT QA Extraction] → [Simple Parser] → Structured KPIs\n",
    "                      ↓                                            ↓\n",
    "                (Skip if no numbers)                    (Already understands temporal relations)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2707ac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joems\\miniconda3\\envs\\finrag_mlops\\Lib\\site-packages\\torch\\cuda\\__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Environment Check ===\n",
      "Python: 3.11.14 | packaged by conda-forge | (main, Oct 13 2025, 14:00:26) [MSC v.1944 64 bit (AMD64)]\n",
      "PyTorch: 2.5.1\n",
      "Transformers: 4.57.1\n",
      "Polars: 1.34.0\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3080 Ti Laptop GPU\n",
      "GPU Memory: 17.18 GB\n",
      "\n",
      "=== Testing Transformers ===\n",
      "✅ Tokenizer loaded\n",
      "\n",
      "=== Testing Polars ===\n",
      "✅ Polars DataFrame created: shape (3, 1)\n",
      "\n",
      "✅ All systems operational!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import transformers\n",
    "import polars as pl\n",
    "\n",
    "print(\"=== Environment Check ===\")\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Transformers: {transformers.__version__}\")\n",
    "print(f\"Polars: {pl.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# transformer test\n",
    "from transformers import AutoTokenizer\n",
    "print(\"\\n=== Testing Transformers ===\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "print(\"✅ Tokenizer loaded\")\n",
    "\n",
    "\n",
    "print(\"\\n=== Testing Polars ===\")\n",
    "df = pl.DataFrame({\"a\": [1, 2, 3]})\n",
    "print(f\"✅ Polars DataFrame created: shape {df.shape}\")\n",
    "\n",
    "print(\"\\n✅ All systems operational!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8454cb6",
   "metadata": {},
   "source": [
    "## Notes for learning / Recap:\n",
    "\n",
    "1. Best Alternative: mrm8488/bert-small-finetuned-squadv2 (faster, similar accuracy) or google/flan-t5-base (can output structured text directly)\n",
    "2. RoBERTa-base-squad2 is optimized for question answering\n",
    "3. FinBERT is optimized for sentiment classification in financial text: Not trained for: \"Extract the revenue value from this text\".\n",
    "\n",
    "### What pipeline() does internally:\n",
    "    ```\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")`\n",
    "    ```\n",
    "- Is equivalent to:\n",
    "    ```\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "    ```\n",
    "\n",
    "- Tokenize - Get model outputs - Extract answer span (first logits and last logits) - Convert tokens back to text.\n",
    "- Pipeline does ALL of this with one call:\n",
    "    ```\n",
    "    def manual_qa(question, context):\n",
    "        # Tokenize\n",
    "        inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "        \n",
    "        # Get model outputs\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        # Extract answer span\n",
    "        answer_start = torch.argmax(outputs.start_logits)\n",
    "        answer_end = torch.argmax(outputs.end_logits)\n",
    "        \n",
    "        # Convert tokens back to text\n",
    "        answer = tokenizer.decode(inputs[\"input_ids\"][0][answer_start:answer_end+1])\n",
    "        \n",
    "        return answer\n",
    "    ```\n",
    "\n",
    "\n",
    "### BatchProcessor Design Pattern\n",
    "1. BatchProcessor implements the Strategy Pattern - it encapsulates the algorithm for processing batches\n",
    "```\n",
    "# Why we use a separate class:\n",
    "    class BatchProcessor:\n",
    "        def __init__(self, qa_pipeline, batch_size=32):\n",
    "            self.qa_pipeline = qa_pipeline  # Dependency injection\n",
    "            self.parser = KPIParser()       # Composition\n",
    "        \n",
    "        def process_batch(self, sentences, metadata):\n",
    "            # Encapsulates the complex batch logic\n",
    "            # Makes testing easier\n",
    "            # Can swap implementations\n",
    "```\n",
    "\n",
    "\n",
    "2. `self.parser.parse_answer(answer, sentence, metadata)`\n",
    "- KPIParser.parse_answer(answer, sentence, metadata). \n",
    "\n",
    "3. `for index, row in df.iterrows():` is slower, we prefer now `for row in df.iter_rows(named=True):`\n",
    "- named true gives dict-like and named false returns tuple-like rows.\n",
    "```\n",
    "    # Example:\n",
    "    df = pl.DataFrame({'ticker': ['AAPL', 'MSFT'], 'value': [100, 200]})\n",
    "\n",
    "    # Without named=True:\n",
    "    for row in df.iter_rows():\n",
    "        print(row)  # ('AAPL', 100), ('MSFT', 200)\n",
    "        \n",
    "    # With named=True:\n",
    "    for row in df.iter_rows(named=True):\n",
    "        print(row)  # {'ticker': 'AAPL', 'value': 100}\n",
    "        print(row['ticker'])  # Direct access by name\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ce6d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready\n"
     ]
    }
   ],
   "source": [
    "## CODE which has - FORMATTED CELL TABLES - Opens a DOM in Jupyter with CSS styling.\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, os\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "SRC = PROJECT_ROOT / \"src\"\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(PROJECT_ROOT / \"assets\" / \"config.env\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from itables import init_notebook_mode, show\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def display_table_with_html(df, title=\"\"):\n",
    "    \"\"\"Display pandas DataFrame as styled HTML table\"\"\"\n",
    "    display(HTML(f\"<h3>{title}</h3>\"))\n",
    "    html_str = df.to_html(classes='table table-striped table-hover', border=0)\n",
    "    display(HTML(html_str))\n",
    "\n",
    "print(\"Environment ready\")\n",
    "\n",
    "# # Load dataset\n",
    "# DATA_PATH = Path(\"../data/exports/sec_filings_small_full.parquet\")\n",
    "# df = pl.read_parquet(DATA_PATH)\n",
    "\n",
    "# print(f\"Dataset loaded: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "# print(f\"Memory usage: {df.estimated_size('mb'):.1f} MB\")\n",
    "\n",
    "## ------------------------------------------------------------------------------------------------\n",
    "## Display functions for sentences with HTML/CSS styling\n",
    "\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import textwrap\n",
    "\n",
    "def display_full_sentences(df, max_rows=50, wrap_length=120, table_height=\"600px\"):\n",
    "    \"\"\"\n",
    "    Display dataframe with wrapped sentences in a scrollable table.\n",
    "    \n",
    "    Args:\n",
    "        df: Polars DataFrame to display\n",
    "        max_rows: Maximum rows to display (default 50)\n",
    "        wrap_length: Characters per line for sentence wrapping (default 120)\n",
    "        table_height: Height of scrollable area (default \"600px\")\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define which columns to display and their widths\n",
    "    display_cols = [\"name\", \"year\", \"section\", \"sentenceID\", \"sentence\", \"likely_kpi\", \"has_numbers\"]\n",
    "    \n",
    "    # Create HTML with custom CSS\n",
    "    ##  ## 'Courier New', monospace;\n",
    "\n",
    "    html_content = f\"\"\"\n",
    "    <style>\n",
    "        .sentence-table {{\n",
    "            border-collapse: collapse;\n",
    "            width: 100%;\n",
    "            font-size: 12px;\n",
    "            font-family: 'Consolas', monospace;\n",
    "            background-color: #1e1e1e;          /* Dark background */\n",
    "            color: #d4d4d4;                     /* Light gray text */\n",
    "        }}\n",
    "        .sentence-table th {{\n",
    "            background-color: #2d2d30;          /* Dark gray header */\n",
    "            color: #4EC9B0;                     /* Teal text for headers */\n",
    "\n",
    "            padding: 8px;\n",
    "            text-align: left;\n",
    "            position: sticky;\n",
    "            top: 0;\n",
    "            z-index: 10;\n",
    "        }}\n",
    "        .sentence-table td {{\n",
    "            border: 1px solid #ddd;\n",
    "            padding: 8px;\n",
    "            vertical-align: top;\n",
    "        }}\n",
    "        .sentence-table tr: {{\n",
    "            background-color: #1e1e1e;\n",
    "        }}\n",
    "        .sentence-table tr:hover {{\n",
    "            background-color: #2a2d2e;          /* Subtle hover effect */\n",
    "            color: #ffffff;                     /* Brighter text on hover */\n",
    "        }}\n",
    "        .sentence-cell {{\n",
    "            white-space: pre-wrap;\n",
    "            word-wrap: break-word;\n",
    "            max-width: 600px;\n",
    "            line-height: 1.5;                    /* CHANGE LINE SPACING HERE */\n",
    "            color: #d4d4d4;                     /* Light gray for sentences */\n",
    "            font-weight: 400;                   /* CHANGE FONT WEIGHT HERE */\n",
    "        }}\n",
    "        .table-container {{\n",
    "            height: {table_height};\n",
    "            overflow: auto;\n",
    "            border: 2px solid #4CAF50;\n",
    "            position: relative;\n",
    "        }}\n",
    "        .kpi-true {{\n",
    "            background-color: #3a3a00 !important;  /* Very dark yellow/gold */\n",
    "            color: #ffeb3b !important;             /* Light yellow text for KPI rows */\n",
    "        }}\n",
    "        .has-numbers {{\n",
    "            font-weight: bold;\n",
    "            color: #569cd6;                        /* Light blue for numbers */\n",
    "        }}\n",
    "        .metadata {{\n",
    "            color: #808080;                        /* Gray for metadata */\n",
    "            font-size: 11px;\n",
    "            background-color: #1e1e1e;\n",
    "            padding: 5px;\n",
    "        }}\n",
    "\n",
    "        /* Custom scrollbar for better dark mode */\n",
    "        .table-container::-webkit-scrollbar {{\n",
    "            width: 12px;\n",
    "            height: 12px;\n",
    "        }}\n",
    "        .table-container::-webkit-scrollbar-track {{\n",
    "            background: #2d2d30;\n",
    "        }}\n",
    "        .table-container::-webkit-scrollbar-thumb {{\n",
    "            background: #555;\n",
    "            border-radius: 6px;\n",
    "        }}\n",
    "        .table-container::-webkit-scrollbar-thumb:hover {{\n",
    "            background: #007ACC;\n",
    "        }}\n",
    "\n",
    "    </style>\n",
    "    \n",
    "    <div class=\"table-container\">\n",
    "        <table class=\"sentence-table\">\n",
    "            <thead>\n",
    "                <tr>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add headers\n",
    "    for col in display_cols:\n",
    "        width = \"40%\" if col == \"sentence\" else \"auto\"\n",
    "        html_content += f\"<th style='width: {width}'>{col}</th>\"\n",
    "    html_content += \"</tr></thead><tbody>\"\n",
    "    \n",
    "    # Add data rows\n",
    "    for i, row in enumerate(df.head(max_rows).iter_rows(named=True)):\n",
    "        if i >= max_rows:\n",
    "            break\n",
    "            \n",
    "        kpi_class = \"kpi-true\" if row.get('likely_kpi', False) else \"\"\n",
    "        html_content += f\"<tr class='{kpi_class}'>\"\n",
    "        \n",
    "        for col in display_cols:\n",
    "            value = row.get(col, \"\")\n",
    "            \n",
    "            if col == \"sentence\":\n",
    "                # Wrap long sentences\n",
    "                if isinstance(value, str):\n",
    "                    wrapped = textwrap.fill(value, width=wrap_length)\n",
    "                    html_content += f\"<td class='sentence-cell'>{wrapped}</td>\"\n",
    "                else:\n",
    "                    html_content += f\"<td>{value}</td>\"\n",
    "            elif col in [\"likely_kpi\", \"has_numbers\"]:\n",
    "                # Format boolean values\n",
    "                display_val = \"✓\" if value else \"-\"\n",
    "                extra_class = \"has-numbers\" if col == \"has_numbers\" and value else \"\"\n",
    "                html_content += f\"<td class='{extra_class}'>{display_val}</td>\"\n",
    "            elif col == \"section\":\n",
    "                # Add section names\n",
    "                section_names = {0: \"Bus\", 1: \"Risk\", 8: \"MD&A\", 9: \"FinStmt\", 10: \"Notes\", 11: \"MktRisk\"}\n",
    "                section_name = section_names.get(value, str(value))\n",
    "                html_content += f\"<td>{value} ({section_name})</td>\"\n",
    "            else:\n",
    "                html_content += f\"<td>{value}</td>\"\n",
    "        \n",
    "        html_content += \"</tr>\"\n",
    "    \n",
    "    html_content += f\"\"\"\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </div>\n",
    "    <div class='metadata'>\n",
    "        Displaying {min(max_rows, len(df))} of {len(df)} total rows | \n",
    "        Wrap: {wrap_length} chars | \n",
    "        Scroll both directions enabled\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(html_content))\n",
    "    \n",
    "#: Simple wrap function for single column display\n",
    "def display_sentences_simple(df, sentence_col=\"sentence\", wrap_at=150):\n",
    "    \"\"\"\n",
    "    Simpler display focusing just on sentences with metadata\n",
    "    \"\"\"\n",
    "    html = \"<div style='height: 600px; overflow-y: scroll; border: 1px solid #ccc; padding: 10px;'>\"\n",
    "    \n",
    "    for row in df.head(100).iter_rows(named=True):\n",
    "        wrapped_sentence = textwrap.fill(row[sentence_col], width=wrap_at)\n",
    "        \n",
    "        html += f\"\"\"\n",
    "        <div style='margin-bottom: 15px; padding: 10px; background: #f9f9f9; border-left: 3px solid #4CAF50;'>\n",
    "            <div style='color: #666; font-size: 11px; margin-bottom: 5px;'>\n",
    "                <strong>{row['name']}</strong> | Year: {row.get('year', 'N/A')} | \n",
    "                Section: {row.get('section', 'N/A')} | ID: {row.get('sentenceID', 'N/A')}\n",
    "            </div>\n",
    "            <div style='font-family: monospace; font-size: 12px; white-space: pre-wrap;'>\n",
    "{wrapped_sentence}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    html += \"</div>\"\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df49431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "019810a1",
   "metadata": {},
   "source": [
    "## Model Download Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8596034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DOWNLOADING MODELS FOR KPI EXTRACTION\n",
      "============================================================\n",
      "\n",
      "📥 Downloading: mrm8488/bert-small-finetuned-squadv2\n",
      "   Description: QA - 42MB, fastest\n",
      "   - Downloading tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joems\\miniconda3\\envs\\finrag_mlops\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\joems\\.cache\\huggingface\\hub\\models--mrm8488--bert-small-finetuned-squadv2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Downloading model weights...\n",
      "   ❌ Failed: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "\n",
      "📥 Downloading: distilbert-base-cased-distilled-squad\n",
      "   Description: QA - 261MB, balanced\n",
      "   - Downloading tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joems\\miniconda3\\envs\\finrag_mlops\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\joems\\.cache\\huggingface\\hub\\models--distilbert-base-cased-distilled-squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Downloading model weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Model loaded to GPU\n",
      "   - Testing model...\n",
      "   ✅ Success! Downloaded in 37.8s\n",
      "   Test result: $2.5 billion (confidence: 0.891)\n",
      "\n",
      "📥 Downloading: deepset/roberta-base-squad2\n",
      "   Description: QA - 496MB, most accurate\n",
      "   - Downloading tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joems\\miniconda3\\envs\\finrag_mlops\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\joems\\.cache\\huggingface\\hub\\models--deepset--roberta-base-squad2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Downloading model weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Model loaded to GPU\n",
      "   - Testing model...\n",
      "   ✅ Success! Downloaded in 2.1s\n",
      "   Test result: $2.5 billion (confidence: 0.426)\n",
      "\n",
      "============================================================\n",
      "DOWNLOAD COMPLETE - Models are cached for future use\n",
      "============================================================\n",
      "\n",
      "Cache location: C:\\Users\\joems\\.cache\\huggingface\n",
      "Total cache size: 27.88 GB\n"
     ]
    }
   ],
   "source": [
    "# Download the best models for KPI extraction\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def download_models():\n",
    "    \"\"\"Download and cache the best models for KPI extraction\"\"\"\n",
    "    \n",
    "    models_to_download = [\n",
    "        (\"mrm8488/bert-small-finetuned-squadv2\", \"QA - 42MB, fastest\"),\n",
    "        (\"distilbert-base-cased-distilled-squad\", \"QA - 261MB, balanced\"),\n",
    "        (\"deepset/roberta-base-squad2\", \"QA - 496MB, most accurate\")\n",
    "    ]\n",
    "        \n",
    "    print(\"=\"*60)\n",
    "    print(\"DOWNLOADING MODELS FOR KPI EXTRACTION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for model_name, description in models_to_download:\n",
    "        print(f\"\\n📥 Downloading: {model_name}\")\n",
    "        print(f\"   Description: {description}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            # Download tokenizer\n",
    "            print(\"   - Downloading tokenizer...\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            \n",
    "            # Download model\n",
    "            print(\"   - Downloading model weights...\")\n",
    "            model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "            \n",
    "            # Move to GPU to verify it works\n",
    "            if torch.cuda.is_available():\n",
    "                model = model.cuda()\n",
    "                print(\"   - Model loaded to GPU\")\n",
    "            \n",
    "            # Test the model\n",
    "            print(\"   - Testing model...\")\n",
    "            qa_pipeline = pipeline(\n",
    "                \"question-answering\",\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                device=0 if torch.cuda.is_available() else -1\n",
    "            )\n",
    "            \n",
    "            result = qa_pipeline(\n",
    "                question=\"What is the revenue?\",\n",
    "                context=\"The company reported revenue of $2.5 billion in 2023.\"\n",
    "            )\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"   ✅ Success! Downloaded in {elapsed:.1f}s\")\n",
    "            print(f\"   Test result: {result['answer']} (confidence: {result['score']:.3f})\")\n",
    "            \n",
    "            # Clear from GPU to save memory\n",
    "            if torch.cuda.is_available():\n",
    "                del model\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Failed: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DOWNLOAD COMPLETE - Models are cached for future use\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Show cache location\n",
    "    from pathlib import Path\n",
    "    cache_dir = Path.home() / \".cache\" / \"huggingface\"\n",
    "    print(f\"\\nCache location: {cache_dir}\")\n",
    "    \n",
    "    # Show cache size\n",
    "    total_size = sum(f.stat().st_size for f in cache_dir.rglob('*') if f.is_file())\n",
    "    print(f\"Total cache size: {total_size / 1e9:.2f} GB\")\n",
    "\n",
    "# Run the download\n",
    "download_models()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bc58761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 100 random sentences from 1003534 total\n",
      "Key signals: 26 likely KPIs, 21 with numbers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .sentence-table {\n",
       "            border-collapse: collapse;\n",
       "            width: 100%;\n",
       "            font-size: 12px;\n",
       "            font-family: 'Segoe UI', Tahoma, sans-serif;\n",
       "            background-color: #1e1e1e;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .sentence-table th {\n",
       "            background-color: #2d2d30;\n",
       "            color: #4EC9B0;\n",
       "            padding: 10px;\n",
       "            text-align: left;\n",
       "            position: sticky;\n",
       "            top: 0;\n",
       "            z-index: 10;\n",
       "            border-bottom: 2px solid #007ACC;\n",
       "        }\n",
       "        .sentence-table td {\n",
       "            border: 1px solid #3a3a3a;\n",
       "            padding: 8px;\n",
       "            vertical-align: top;\n",
       "        }\n",
       "        .sentence-table tr:hover {\n",
       "            background-color: #2a2d2e;\n",
       "        }\n",
       "        .sentence-cell {\n",
       "            white-space: pre-wrap;\n",
       "            word-wrap: break-word;\n",
       "            max-width: 800px;\n",
       "            min-width: 400px;\n",
       "            line-height: 1.4;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "        }\n",
       "        .table-container {\n",
       "            height: 700px;\n",
       "            overflow: auto;\n",
       "            border: 1px solid #007ACC;\n",
       "        }\n",
       "        .kpi-true {\n",
       "            background-color: #2a3f2a !important;\n",
       "        }\n",
       "        .flag-true {\n",
       "            color: #4EC9B0;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .metadata {\n",
       "            color: #808080;\n",
       "            font-size: 11px;\n",
       "            padding: 10px;\n",
       "            background-color: #1e1e1e;\n",
       "        }\n",
       "    </style>\n",
       "\n",
       "    <div class=\"table-container\">\n",
       "        <table class=\"sentence-table\">\n",
       "            <thead>\n",
       "                <tr>\n",
       "    <th style='width: 10%'>name</th><th style='width: auto'>tickers</th><th style='width: auto'>section</th><th style='width: auto'>report_year</th><th style='width: auto'>reportDate</th><th style='width: 50%'>sentence</th><th style='width: 5%'>likely_kpi</th><th style='width: 5%'>has_numbers</th><th style='width: auto'>is_table_like</th><th style='width: auto'>has_forward_looking</th><th style='width: auto'>sentenceID</th><th style='width: auto'>docID</th><th style='width: auto'>cik</th></tr></thead><tbody><tr class=''><td>GENWORTH FINANCIAL INC</td><td>GNW</td><td>10 (Notes)</td><td>2011</td><td>2011-12-31</td><td class='sentence-cell'>GENWORTH FINANCIAL, INC. NOTES TO CONSOLIDATED FINANCIAL STATEMENTS Years Ended December 31, 2011, 2010 and 2009 In June 2011, we received a subpoena\n",
       "from the office of the New York Attorney General relating to an industry-wide investigation of unclaimed property and escheatment practices and\n",
       "procedures.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001276520_10-K_2011_section_8_1338</td><td>0001276520_10-K_2011</td><td>0001276520</td></tr><tr class=''><td>EXXON MOBIL CORP</td><td>XOM</td><td>3 (3)</td><td>2017</td><td>2017-12-31</td><td class='sentence-cell'>The Corporation anticipates several projects will come online over the next few years providing additional production capacity.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0000034088_10-K_2017_section_2_10</td><td>0000034088_10-K_2017</td><td>0000034088</td></tr><tr class=''><td>HANOVER INSURANCE GROUP, INC.</td><td>THG</td><td>12 (12)</td><td>2017</td><td>2017-12-31</td><td class='sentence-cell'>The effectiveness of our internal control over financial reporting as of December 31, 2017 has been audited by PricewaterhouseCoopers LLP, an\n",
       "independent registered public accounting firm, as stated in their report which is included herein.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000944695_10-K_2017_section_9A_14</td><td>0000944695_10-K_2017</td><td>0000944695</td></tr><tr class=''><td>PNM RESOURCES INC</td><td>PNM</td><td>10 (Notes)</td><td>2013</td><td>2013-12-31</td><td class='sentence-cell'>The parties agreed to a settlement of the case, which was approved by the PUCT in May 2011.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001108426_10-K_2013_section_8_1616</td><td>0001108426_10-K_2013</td><td>0001108426</td></tr><tr class=''><td>FIRST BANCORP /PR/</td><td>FBP</td><td>10 (Notes)</td><td>2017</td><td>2017-12-31</td><td class='sentence-cell'>In the case of credit cards and personal lines of credit, the Corporation can cancel the unused credit facility at any time and without cause.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001057706_10-K_2017_section_8_1494</td><td>0001057706_10-K_2017</td><td>0001057706</td></tr><tr class=''><td>GENWORTH FINANCIAL INC</td><td>GNW</td><td>8 (MD&A)</td><td>2019</td><td>2019-12-31</td><td class='sentence-cell'>As of December 31, 2019 and 2018, the PMIERs sufficiency ratios were in excess of $1.0 billion and $750 million, respectively, of available assets\n",
       "above the current and previous PMIERs requirements, respectively.</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001276520_10-K_2019_section_7_683</td><td>0001276520_10-K_2019</td><td>0001276520</td></tr><tr class=''><td>NETFLIX INC</td><td>NFLX</td><td>0 (Business)</td><td>2006</td><td>2006-12-31</td><td class='sentence-cell'>In this Annual Report on Form 10-K, “Netflix,” the “Company,” “we” and the “registrant” refer to Netflix, Inc. Our investor relations Web site is\n",
       "located at http://ir.netflix.com.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001065280_10-K_2006_section_1_201</td><td>0001065280_10-K_2006</td><td>0001065280</td></tr><tr class=''><td>GENWORTH FINANCIAL INC</td><td>GNW</td><td>10 (Notes)</td><td>2019</td><td>2019-12-31</td><td class='sentence-cell'>As of December 31, 2019 and 2018, the accumulated postretirement benefit obligation associated with these benefits was $71 million and $65 million,\n",
       "respectively, which we accrued in other liabilities in the consolidated balance sheets.</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001276520_10-K_2019_section_8_709</td><td>0001276520_10-K_2019</td><td>0001276520</td></tr><tr class=''><td>HAWAIIAN ELECTRIC INDUSTRIES INC</td><td>HE</td><td>10 (Notes)</td><td>2018</td><td>2018-12-31</td><td class='sentence-cell'>• Service Reliability Performance measured by System Average Interruption Duration and Frequency Indexes (penalties only).</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000354707_10-K_2018_section_8_658</td><td>0000354707_10-K_2018</td><td>0000354707</td></tr><tr class=''><td>GOODYEAR TIRE & RUBBER CO /OH/</td><td>GT</td><td>10 (Notes)</td><td>2014</td><td>2014-12-31</td><td class='sentence-cell'>16, Pension, Other Postretirement Benefits and Savings Plans.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0000042582_10-K_2014_section_8_749</td><td>0000042582_10-K_2014</td><td>0000042582</td></tr><tr class='kpi-true'><td>WASHINGTON TRUST BANCORP INC</td><td>WASH</td><td>0 (Business)</td><td>2014</td><td>2014-12-31</td><td class='sentence-cell'>The Bank also has a limited liability company subsidiary that serves as a special limited partner responsible for certain administrative functions\n",
       "associated with the Bank’s investment in two real estate limited partnerships.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000737468_10-K_2014_section_1_117</td><td>0000737468_10-K_2014</td><td>0000737468</td></tr><tr class=''><td>Apple Inc.</td><td>AAPL</td><td>0 (Business)</td><td>2015</td><td>2015-09-26</td><td class='sentence-cell'>The Company’s fiscal year is the 52 or 53-week period that ends on the last Saturday of September.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000320193_10-K_2015_section_1_7</td><td>0000320193_10-K_2015</td><td>0000320193</td></tr><tr class=''><td>GENWORTH FINANCIAL INC</td><td>GNW</td><td>10 (Notes)</td><td>2013</td><td>2013-12-31</td><td class='sentence-cell'>All assets and liabilities carried at fair value are classified and disclosed in one of the following three categories: • Level 1-Quoted prices for\n",
       "identical instruments in active markets.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001276520_10-K_2013_section_8_105</td><td>0001276520_10-K_2013</td><td>0001276520</td></tr><tr class=''><td>Mastercard Inc</td><td>MA</td><td>10 (Notes)</td><td>2020</td><td>2020-12-31</td><td class='sentence-cell'>Defined Contribution Plans The Company sponsors defined contribution retirement plans.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0001141391_10-K_2020_section_8_424</td><td>0001141391_10-K_2020</td><td>0001141391</td></tr><tr class=''><td>BlackRock Inc.</td><td>BLK</td><td>7 (MD&A(old))</td><td>2019</td><td>2019-12-31</td><td class='sentence-cell'>(4) Amounts include assets held by consolidated sponsored investment products.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001364742_10-K_2019_section_6_13</td><td>0001364742_10-K_2019</td><td>0001364742</td></tr><tr class=''><td>MICROSOFT CORP</td><td>MSFT</td><td>1 (Risk)</td><td>2020</td><td>2020-06-30</td><td class='sentence-cell'>These costs will reduce the operating margins we have previously achieved.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000789019_10-K_2020_section_1A_53</td><td>0000789019_10-K_2020</td><td>0000789019</td></tr><tr class=''><td>AMERICAN STATES WATER CO</td><td>AWR</td><td>8 (MD&A)</td><td>2013</td><td>2013-12-31</td><td class='sentence-cell'>One of these areas is the Nipomo Mesa of the Santa Maria Groundwater Basin.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001056903_10-K_2013_section_7_847</td><td>0001056903_10-K_2013</td><td>0001056903</td></tr><tr class=''><td>ICAHN ENTERPRISES L.P.</td><td>IEP</td><td>19 (Exhibits)</td><td>2006</td><td>2006-12-31</td><td class='sentence-cell'>1-9516), filed on November 9, 2004).</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000813762_10-K_2006_section_15_104</td><td>0000813762_10-K_2006</td><td>0000813762</td></tr><tr class=''><td>FIRST BANCORP /PR/</td><td>FBP</td><td>14 (14)</td><td>2010</td><td>2010-12-31</td><td class='sentence-cell'>• The compensation structure has a balance between performance objectives and risk management measures to prevent the taking of excessive risks.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001057706_10-K_2010_section_10_419</td><td>0001057706_10-K_2010</td><td>0001057706</td></tr><tr class=''><td>BOEING CO</td><td>BA</td><td>8 (MD&A)</td><td>2013</td><td>2013-12-31</td><td class='sentence-cell'>Advances and progress billings increased by $3.9 billion in 2013, $1.9 billion in 2012 and $5 billion in 2011, primarily due to payments from\n",
       "commercial airplane customers.</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000012927_10-K_2013_section_7_314</td><td>0000012927_10-K_2013</td><td>0000012927</td></tr><tr class=''><td>CNA FINANCIAL CORP</td><td>CNA</td><td>1 (Risk)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>Our efforts or the efforts of agents and brokers with respect to new products or alternate distribution channels, as well as changes in the way agents\n",
       "and brokers utilize greater levels of data and technology, could adversely impact our business relationship with independent agents and brokers who\n",
       "currently market our products, resulting in a lower volume and/or profitability of business generated from these sources.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000021175_10-K_2016_section_1A_96</td><td>0000021175_10-K_2016</td><td>0000021175</td></tr><tr class=''><td>AVISTA CORP</td><td>AVA</td><td>2 (2)</td><td>2011</td><td>2011-12-31</td><td class='sentence-cell'>Unresolved Staff Comments As of the filing date of this Annual Report on Form 10-K, we have no unresolved comments from the staff of the Securities\n",
       "and Exchange Commission.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000104918_10-K_2011_section_1B_1</td><td>0000104918_10-K_2011</td><td>0000104918</td></tr><tr class='kpi-true'><td>Meta Platforms, Inc.</td><td>META</td><td>10 (Notes)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>We have previously accrued an estimated unrecognized tax benefit consistent with the guidance in ASC 740 that is lower than the potential additional\n",
       "federal tax liability of $3.0 to $5.0 billion in excess of the originally filed U.S. return, plus interest and penalties.</td><td class='flag-true'>✓</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0001326801_10-K_2016_section_8_367</td><td>0001326801_10-K_2016</td><td>0001326801</td></tr><tr class='kpi-true'><td>RADIAN GROUP INC</td><td>RDN</td><td>10 (Notes)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>(2) Does not include certain other invested assets ($1.2 million), primarily invested in limited partnerships, accounted for as cost-method\n",
       "investments and not measured at fair value.</td><td class='flag-true'>✓</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000890926_10-K_2016_section_8_454</td><td>0000890926_10-K_2016</td><td>0000890926</td></tr><tr class=''><td>UNITEDHEALTH GROUP INC</td><td>UNH</td><td>12 (12)</td><td>2006</td><td>2006-12-31</td><td class='sentence-cell'>The Company’s internal control system is designed to provide reasonable assurance to our management and board of directors regarding the reliability\n",
       "of financial reporting and the preparation of financial statements for external purposes in accordance with generally accepted accounting principles.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000731766_10-K_2006_section_9A_32</td><td>0000731766_10-K_2006</td><td>0000731766</td></tr><tr class=''><td>THERMO FISHER SCIENTIFIC INC.</td><td>TMO</td><td>8 (MD&A)</td><td>2018</td><td>2018-12-31</td><td class='sentence-cell'>This North America-based business adds complementary cell culture products that expand the segment's bioproduction offerings to help customers\n",
       "increase yield during production of biologic drugs.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000097745_10-K_2018_section_7_26</td><td>0000097745_10-K_2018</td><td>0000097745</td></tr><tr class=''><td>LINCOLN NATIONAL CORP</td><td>LNC</td><td>1 (Risk)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>Further, insurance regulatory authorities have relatively broad discretion to issue orders of supervision, which permit such authorities to supervise\n",
       "the business and operations of an insurance company.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000059558_10-K_2016_section_1A_19</td><td>0000059558_10-K_2016</td><td>0000059558</td></tr><tr class=''><td>MICROSOFT CORP</td><td>MSFT</td><td>0 (Business)</td><td>2020</td><td>2020-06-30</td><td class='sentence-cell'>Mr. Smith also serves on the Board of Directors of Netflix, Inc. PART I Item 1 EMPLOYEES As of June 30, 2020, we employed approximately 163,000 people\n",
       "on a full-time basis, 96,000 in the U.S. and 67,000 internationally.</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000789019_10-K_2020_section_1_259</td><td>0000789019_10-K_2020</td><td>0000789019</td></tr><tr class='kpi-true'><td>AVISTA CORP</td><td>AVA</td><td>10 (Notes)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>When the liability is initially recorded, the associated costs of the ARO are capitalized as part of the carrying amount of the related long-lived\n",
       "asset.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000104918_10-K_2016_section_8_115</td><td>0000104918_10-K_2016</td><td>0000104918</td></tr><tr class='kpi-true'><td>HANOVER INSURANCE GROUP, INC.</td><td>THG</td><td>8 (MD&A)</td><td>2018</td><td>2018-12-31</td><td class='sentence-cell'>For example, for some low volume and high volatility classes of business, special reserving techniques are utilized that estimate IBNR by selecting\n",
       "the loss ratio that balances actual reported losses to expected reported losses as defined by the estimated underlying reporting pattern.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0000944695_10-K_2018_section_7_252</td><td>0000944695_10-K_2018</td><td>0000944695</td></tr><tr class=''><td>Apple Inc.</td><td>AAPL</td><td>0 (Business)</td><td>2018</td><td>2018-09-29</td><td class='sentence-cell'>Mac Mac is the Company’s line of desktop and portable personal computers based on its macOS operating system.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000320193_10-K_2018_section_1_26</td><td>0000320193_10-K_2018</td><td>0000320193</td></tr><tr class='kpi-true'><td>PNM RESOURCES INC</td><td>PNM</td><td>10 (Notes)</td><td>2018</td><td>2018-12-31</td><td class='sentence-cell'>Amortization of the lease obligation and the right-of-use asset for certain leases, primarily those classified as operating leases, will be on a\n",
       "straight-line basis and other leases will be required to be accounted for as financing arrangements, which are recorded in a manner that is similar to\n",
       "the accounting for capital leases under current GAAP.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001108426_10-K_2018_section_8_258</td><td>0001108426_10-K_2018</td><td>0001108426</td></tr><tr class='kpi-true'><td>GOODYEAR TIRE & RUBBER CO /OH/</td><td>GT</td><td>1 (Risk)</td><td>2014</td><td>2014-12-31</td><td class='sentence-cell'>As of December 31, 2014, we had approximately $2.2 billion of variable rate debt outstanding.</td><td class='flag-true'>✓</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000042582_10-K_2014_section_1A_142</td><td>0000042582_10-K_2014</td><td>0000042582</td></tr><tr class=''><td>AbbVie Inc.</td><td>ABBV</td><td>10 (Notes)</td><td>2020</td><td>2020-12-31</td><td class='sentence-cell'>AbbVie’s payable to Janssen, included in accounts payable and accrued liabilities, was $562 million at December 31, 2020 and $455 million at December\n",
       "31, 2019.</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001551152_10-K_2020_section_8_259</td><td>0001551152_10-K_2020</td><td>0001551152</td></tr><tr class=''><td>MICROSOFT CORP</td><td>MSFT</td><td>10 (Notes)</td><td>2018</td><td>2018-06-30</td><td class='sentence-cell'>Capitalized software development costs are amortized over the estimated lives of the products.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0000789019_10-K_2018_section_8_81</td><td>0000789019_10-K_2018</td><td>0000789019</td></tr><tr class=''><td>BOK FINANCIAL CORP</td><td>BOKF</td><td>1 (Risk)</td><td>2020</td><td>2020-12-31</td><td class='sentence-cell'>BOK Financial’s subsidiary bank may rely on other financial institutions and the Federal Home Loan Bank of Topeka as a significant source of funds.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000875357_10-K_2020_section_1A_126</td><td>0000875357_10-K_2020</td><td>0000875357</td></tr><tr class='kpi-true'><td>NVIDIA CORP</td><td>NVDA</td><td>19 (Exhibits)</td><td>2019</td><td>2019-01-27</td><td class='sentence-cell'>As a result, at January 28, 2018 we had recorded a provisional income tax expense of $43 million on the write-down of our deferred tax balance.</td><td class='flag-true'>✓</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001045810_10-K_2019_section_15_386</td><td>0001045810_10-K_2019</td><td>0001045810</td></tr><tr class=''><td>BGC Partners, Inc.</td><td>BGCP</td><td>0 (Business)</td><td>2015</td><td>2015-12-31</td><td class='sentence-cell'>The reforms are designed to reduce systemic risk and bring more transparency to both OTC and listed derivatives markets.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001094831_10-K_2015_section_1_403</td><td>0001094831_10-K_2015</td><td>0001094831</td></tr><tr class=''><td>BlackRock Inc.</td><td>BLK</td><td>8 (MD&A)</td><td>2018</td><td>2018-12-31</td><td class='sentence-cell'>The Company had a 40% stake in the joint venture, which managed and marketed a range of co-branded mutual funds in India.</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001364742_10-K_2018_section_7_32</td><td>0001364742_10-K_2018</td><td>0001364742</td></tr><tr class=''><td>ICAHN ENTERPRISES L.P.</td><td>IEP</td><td>8 (MD&A)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>In response to changes in customer demand, our Railcar segment continues to adjust production rates at its railcar manufacturing facilities.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000813762_10-K_2016_section_7_159</td><td>0000813762_10-K_2016</td><td>0000813762</td></tr><tr class=''><td>MARATHON OIL CORP</td><td>MRO</td><td>1 (Risk)</td><td>2013</td><td>2013-12-31</td><td class='sentence-cell'>Consideration of new federal regulation and increased state oversight continues to arise.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000101778_10-K_2013_section_1A_67</td><td>0000101778_10-K_2013</td><td>0000101778</td></tr><tr class='kpi-true'><td>Mastercard Inc</td><td>MA</td><td>8 (MD&A)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>Net cash used in investing activities increased $452 million in 2016 versus 2015, primarily due to lower sales and maturities of our investment\n",
       "securities, partially offset by cash used for acquisition activities in the prior year.</td><td class='flag-true'>✓</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001141391_10-K_2016_section_7_224</td><td>0001141391_10-K_2016</td><td>0001141391</td></tr><tr class='kpi-true'><td>PNM RESOURCES INC</td><td>PNM</td><td>10 (Notes)</td><td>2019</td><td>2019-12-31</td><td class='sentence-cell'>The issues appealed by the various cross-appellants included, among other things, the NMPRC allowing PNM to recover any of the costs of the lease\n",
       "extensions for the 114.6 MW of PVNGS Units 1 and 2 and the purchase price for the 64.1 MW in PVNGS Unit 2, the costs incurred under the Four Corners\n",
       "CSA, and the inclusion of the “prepaid pension asset” in rate base.</td><td class='flag-true'>✓</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001108426_10-K_2019_section_8_1574</td><td>0001108426_10-K_2019</td><td>0001108426</td></tr><tr class=''><td>BOEING CO</td><td>BA</td><td>8 (MD&A)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>During 2015, we recorded charges of $835 million: $513 million at Commercial Airplanes and $322 million at our BMA segment.</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000012927_10-K_2016_section_7_31</td><td>0000012927_10-K_2016</td><td>0000012927</td></tr><tr class=''><td>FIRST BANCORP /PR/</td><td>FBP</td><td>10 (Notes)</td><td>2020</td><td>2020-12-31</td><td class='sentence-cell'>The limitation did not impact the USVI operations in 2020 and 2019.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001057706_10-K_2020_section_8_1440</td><td>0001057706_10-K_2020</td><td>0001057706</td></tr><tr class=''><td>PROCTER & GAMBLE Co</td><td>PG</td><td>10 (Notes)</td><td>2017</td><td>2017-06-30</td><td class='sentence-cell'>Cash flows from derivative instruments designated as net investment hedges are classified as financing activities.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000080424_10-K_2017_section_8_90</td><td>0000080424_10-K_2017</td><td>0000080424</td></tr><tr class=''><td>Tesla, Inc.</td><td>TSLA</td><td>1 (Risk)</td><td>2012</td><td>2012-12-31</td><td class='sentence-cell'>In addition, customers have the opportunity to purchase Extended Service plans for the period after the end of the New Vehicle Limited Warranty for\n",
       "the Tesla Roadster to cover additional services for up to an additional three years or 36,000 miles, provided they are purchased within a specified\n",
       "period of time.</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0001318605_10-K_2012_section_1A_649</td><td>0001318605_10-K_2012</td><td>0001318605</td></tr><tr class='kpi-true'><td>Walmart Inc.</td><td>WMT</td><td>8 (MD&A)</td><td>2020</td><td>2020-01-31</td><td class='sentence-cell'>For fiscal 2020, the increase was primarily due to growth in total members, which benefited from higher overall renewal rates and higher Plus Member\n",
       "penetration along with gains on property sales and other income.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000104169_10-K_2020_section_7_185</td><td>0000104169_10-K_2020</td><td>0000104169</td></tr><tr class=''><td>EXXON MOBIL CORP</td><td>XOM</td><td>19 (Exhibits)</td><td>2014</td><td>2014-12-31</td><td class='sentence-cell'>Excluding the impact of the expiry of the Abu Dhabi onshore concession, production decreased 1.7 percent.</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000034088_10-K_2014_section_15_158</td><td>0000034088_10-K_2014</td><td>0000034088</td></tr><tr class=''><td>THERMO FISHER SCIENTIFIC INC.</td><td>TMO</td><td>8 (MD&A)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>The tax provision in the 2014 period was favorably affected by $5.5 million as a result of adjustments to deferred tax balances due to changes in tax\n",
       "rates.</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000097745_10-K_2016_section_7_311</td><td>0000097745_10-K_2016</td><td>0000097745</td></tr><tr class=''><td>INTUIT INC</td><td>INTU</td><td>10 (Notes)</td><td>2017</td><td>2017-07-31</td><td class='sentence-cell'>Certain RSUs granted to senior management vest based on the achievement of pre-established performance or market goals.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000896878_10-K_2017_section_8_228</td><td>0000896878_10-K_2017</td><td>0000896878</td></tr><tr class=''><td>BGC Partners, Inc.</td><td>BGCP</td><td>0 (Business)</td><td>2017</td><td>2017-12-31</td><td class='sentence-cell'>We also benefit from shared referrals and materials from local offices.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001094831_10-K_2017_section_1_250</td><td>0001094831_10-K_2017</td><td>0001094831</td></tr><tr class=''><td>HAWAIIAN ELECTRIC INDUSTRIES INC</td><td>HE</td><td>10 (Notes)</td><td>2018</td><td>2018-12-31</td><td class='sentence-cell'>AES Hawaii, Inc.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000354707_10-K_2018_section_8_526</td><td>0000354707_10-K_2018</td><td>0000354707</td></tr><tr class='kpi-true'><td>OGE ENERGY CORP.</td><td>OGE</td><td>1 (Risk)</td><td>2015</td><td>2015-12-31</td><td class='sentence-cell'>Costs of compliance with environmental laws and regulations are significant and the cost of compliance with future environmental laws and regulations\n",
       "may adversely affect our results of operations, consolidated financial position, or liquidity.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001021635_10-K_2015_section_1A_24</td><td>0001021635_10-K_2015</td><td>0001021635</td></tr><tr class=''><td>JONES LANG LASALLE INC</td><td>JLL</td><td>1 (Risk)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>Seeking Opportunities in Risks.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001037976_10-K_2016_section_1A_42</td><td>0001037976_10-K_2016</td><td>0001037976</td></tr><tr class='kpi-true'><td>RADIAN GROUP INC</td><td>RDN</td><td>1 (Risk)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>Our premium rates take into account, among other factors, LTV, type (e.g., prime vs. non-prime or fixed vs. variable payments), premium structure\n",
       "(e.g., single lump sum, monthly or other variations), term, coverage percentage and whether there is a deductible in front of our loss position.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000890926_10-K_2016_section_1A_192</td><td>0000890926_10-K_2016</td><td>0000890926</td></tr><tr class=''><td>UNITEDHEALTH GROUP INC</td><td>UNH</td><td>1 (Risk)</td><td>2011</td><td>2011-12-31</td><td class='sentence-cell'>Our ability to adequately price our products and services, to provide effective service to our customers in an efficient and uninterrupted fashion,\n",
       "and to accurately report our results of operations depends on the integrity of the data in our information systems.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000731766_10-K_2011_section_1A_278</td><td>0000731766_10-K_2011</td><td>0000731766</td></tr><tr class=''><td>SPX Technologies, Inc.</td><td>SPXC</td><td>10 (Notes)</td><td>2012</td><td>2012-12-31</td><td class='sentence-cell'>We periodically assess the realizability of deferred tax assets and the adequacy of deferred tax liabilities, including the results of local, state,\n",
       "federal or foreign statutory tax audits or estimates and judgments used.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0000088205_10-K_2012_section_8_82</td><td>0000088205_10-K_2012</td><td>0000088205</td></tr><tr class='kpi-true'><td>ASSURED GUARANTY LTD</td><td>AGO</td><td>1 (Risk)</td><td>2010</td><td>2010-12-31</td><td class='sentence-cell'>Instead, the Company recognizes a loss and loss adjustment expense (\"LAE\") reserve on a financial guaranty contract when management expects that the\n",
       "present value of projected loss will exceed the deferred premium revenue for that contract.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0001273813_10-K_2010_section_1A_11</td><td>0001273813_10-K_2010</td><td>0001273813</td></tr><tr class=''><td>AMERICAN STATES WATER CO</td><td>AWR</td><td>1 (Risk)</td><td>2006</td><td>2006-12-31</td><td class='sentence-cell'>As a result, we are currently at risk for increases in spot market prices of electricity that we purchase and for decreases in spot market prices for\n",
       "electricity that we sell.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001056903_10-K_2006_section_1A_77</td><td>0001056903_10-K_2006</td><td>0001056903</td></tr><tr class='kpi-true'><td>FLAGSTAR BANCORP INC</td><td>FBC</td><td>10 (Notes)</td><td>2020</td><td>2020-12-31</td><td class='sentence-cell'>Transfers of Financial Assets Our recognition of gain or loss on the sale of loans for which we surrender control is accounted for as a sale to the\n",
       "extent that 1) the transferred assets are legally isolated from us or our consolidated affiliates, even in bankruptcy or other receivership, 2) the\n",
       "transferee has the right to pledge or exchange the assets with no conditions that constrain the transferee and provide more than a trivial benefit to\n",
       "the Company and 3) we do not maintain the obligation or unilateral ability to reclaim or repurchase the assets.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001033012_10-K_2020_section_8_170</td><td>0001033012_10-K_2020</td><td>0001033012</td></tr><tr class=''><td>FIRST BANCORP /PR/</td><td>FBP</td><td>0 (Business)</td><td>2017</td><td>2017-12-31</td><td class='sentence-cell'>In general, these enforcement actions may be initiated for violations of laws and regulations and for engaging in unsafe or unsound practices.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001057706_10-K_2017_section_1_384</td><td>0001057706_10-K_2017</td><td>0001057706</td></tr><tr class=''><td>NETFLIX INC</td><td>NFLX</td><td>3 (3)</td><td>2010</td><td>2010-12-31</td><td class='sentence-cell'>We believe that our current space will be adequate or that additional space will be available on commercially reasonable terms for the foreseeable\n",
       "future.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0001065280_10-K_2010_section_2_5</td><td>0001065280_10-K_2010</td><td>0001065280</td></tr><tr class=''><td>CHEVRON CORP</td><td>CVX</td><td>12 (12)</td><td>2011</td><td>2011-12-31</td><td class='sentence-cell'>The company’s management, including the Chief Executive Officer and the Chief Financial Officer, conducted an evaluation of the effectiveness of the\n",
       "company’s internal control over financial reporting based on the Internal Control - Integrated Framework issued by the Committee of Sponsoring\n",
       "Organizations of the Treadway Commission.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000093410_10-K_2011_section_9A_4</td><td>0000093410_10-K_2011</td><td>0000093410</td></tr><tr class=''><td>PNM RESOURCES INC</td><td>PNM</td><td>10 (Notes)</td><td>2017</td><td>2017-12-31</td><td class='sentence-cell'>See Note 6 for information on intercompany borrowing arrangements.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001108426_10-K_2017_section_8_359</td><td>0001108426_10-K_2017</td><td>0001108426</td></tr><tr class='kpi-true'><td>MCDONALDS CORP</td><td>MCD</td><td>8 (MD&A)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>In addition, the Company's 2011 and 2012 U.S. federal income tax returns are currently under examination and the completion of the field audit is\n",
       "expected in 2017.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0000063908_10-K_2016_section_7_404</td><td>0000063908_10-K_2016</td><td>0000063908</td></tr><tr class=''><td>Walmart Inc.</td><td>WMT</td><td>10 (Notes)</td><td>2020</td><td>2020-01-31</td><td class='sentence-cell'>We also evaluated the appropriateness of the related disclosures.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000104169_10-K_2020_section_8_27</td><td>0000104169_10-K_2020</td><td>0000104169</td></tr><tr class=''><td>IDACORP INC</td><td>IDA</td><td>8 (MD&A)</td><td>2020</td><td>2020-12-31</td><td class='sentence-cell'>A degree-day measures how much the average daily temperature varies from 65 degrees.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001057877_10-K_2020_section_7_118</td><td>0001057877_10-K_2020</td><td>0001057877</td></tr><tr class=''><td>IDACORP INC</td><td>IDA</td><td>19 (Exhibits)</td><td>2008</td><td>2008-12-31</td><td class='sentence-cell'>LaMont Keen J. LaMont Keen President and Chief Executive Officer Pursuant to the requirements of the Securities Exchange Act of 1934, this report has\n",
       "been signed below by the following persons on behalf of the registrant and in the capacities and on the dates indicated.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001057877_10-K_2008_section_15_19</td><td>0001057877_10-K_2008</td><td>0001057877</td></tr><tr class='kpi-true'><td>ASSURED GUARANTY LTD</td><td>AGO</td><td>10 (Notes)</td><td>2019</td><td>2019-12-31</td><td class='sentence-cell'>The calculation of debt service requires the use of estimates, which the Company updates periodically, including estimates for the expected remaining\n",
       "term of insured obligations supported by homogeneous pools of assets, updated interest rates for floating and variable rate insured obligations,\n",
       "behavior of consumer price indices for obligations with consumer price index inflators, foreign exchange rates and other assumptions based on the\n",
       "characteristics of each insured obligation.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0001273813_10-K_2019_section_8_253</td><td>0001273813_10-K_2019</td><td>0001273813</td></tr><tr class=''><td>Mastercard Inc</td><td>MA</td><td>8 (MD&A)</td><td>2018</td><td>2018-12-31</td><td class='sentence-cell'>We use non-GAAP financial measures to, among other things, evaluate our ongoing operations in relation to historical results, for internal planning\n",
       "and forecasting purposes and in the calculation of performance-based compensation.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001141391_10-K_2018_section_7_52</td><td>0001141391_10-K_2018</td><td>0001141391</td></tr><tr class='kpi-true'><td>SPX Technologies, Inc.</td><td>SPXC</td><td>8 (MD&A)</td><td>2018</td><td>2018-12-31</td><td class='sentence-cell'>The remaining components of pension/postretirement expense, primarily service and interest costs and expected return on plan assets, are recorded on a\n",
       "quarterly basis.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0000088205_10-K_2018_section_7_439</td><td>0000088205_10-K_2018</td><td>0000088205</td></tr><tr class=''><td>AbbVie Inc.</td><td>ABBV</td><td>0 (Business)</td><td>2017</td><td>2017-12-31</td><td class='sentence-cell'>AbbVie has the rights to sell AndroGel, CREON and Synthroid only in the United States.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001551152_10-K_2017_section_1_54</td><td>0001551152_10-K_2017</td><td>0001551152</td></tr><tr class=''><td>LINCOLN NATIONAL CORP</td><td>LNC</td><td>8 (MD&A)</td><td>2006</td><td>2006-12-31</td><td class='sentence-cell'>Financial information in the tables that follow is presented in conformity with accounting principles generally accepted in the United States of\n",
       "America (“GAAP”), unless otherwise indicated.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000059558_10-K_2006_section_7_13</td><td>0000059558_10-K_2006</td><td>0000059558</td></tr><tr class=''><td>COMMERCE BANCSHARES INC /MO/</td><td>CBSH</td><td>8 (MD&A)</td><td>2017</td><td>2017-12-31</td><td class='sentence-cell'>Non-interest bearing deposits increased on average by $126.6 million, or 1.8%, driven by growth in government and personal demand deposits but\n",
       "partially offset by a decline in business demand deposits.</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000022356_10-K_2017_section_7_535</td><td>0000022356_10-K_2017</td><td>0000022356</td></tr><tr class='kpi-true'><td>FIRST BANCORP /PR/</td><td>FBP</td><td>8 (MD&A)</td><td>2009</td><td>2009-12-31</td><td class='sentence-cell'>However, for debt securities for which OTTI was recognized in earnings, the difference between the new amortized cost basis and the cash flows\n",
       "expected to be collected is accreted as interest income.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0001057706_10-K_2009_section_7_88</td><td>0001057706_10-K_2009</td><td>0001057706</td></tr><tr class=''><td>GENWORTH FINANCIAL INC</td><td>GNW</td><td>14 (14)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>Mr. McKay served as our Senior Vice President-Chief Information Officer from January 2009 to January 2015.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001276520_10-K_2016_section_10_56</td><td>0001276520_10-K_2016</td><td>0001276520</td></tr><tr class=''><td>AVISTA CORP</td><td>AVA</td><td>0 (Business)</td><td>2020</td><td>2020-12-31</td><td class='sentence-cell'>Avista Utilities provides electric distribution and transmission, and natural gas distribution services in parts of eastern Washington and northern\n",
       "Idaho.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000104918_10-K_2020_section_1_7</td><td>0000104918_10-K_2020</td><td>0000104918</td></tr><tr class=''><td>CHEVRON CORP</td><td>CVX</td><td>18 (18)</td><td>2018</td><td>2018-12-31</td><td class='sentence-cell'>The company has increased its investment emphasis on short-cycle projects.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0000093410_10-K_2018_section_14_60</td><td>0000093410_10-K_2018</td><td>0000093410</td></tr><tr class=''><td>GOODYEAR TIRE & RUBBER CO /OH/</td><td>GT</td><td>19 (Exhibits)</td><td>2020</td><td>2020-12-31</td><td class='sentence-cell'>(b) Accounts receivable charged off.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000042582_10-K_2020_section_15_15</td><td>0000042582_10-K_2020</td><td>0000042582</td></tr><tr class=''><td>APPLIED MATERIALS INC /DE</td><td>AMAT</td><td>19 (Exhibits)</td><td>2020</td><td>2020-10-25</td><td class='sentence-cell'>Retirement Benefits: Changes to the Disclosure Requirements for Defined Benefit and other Postretirement Plans.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0000006951_10-K_2020_section_15_174</td><td>0000006951_10-K_2020</td><td>0000006951</td></tr><tr class=''><td>ASSURED GUARANTY LTD</td><td>AGO</td><td>10 (Notes)</td><td>2020</td><td>2020-12-31</td><td class='sentence-cell'>Under the PREPA RSA, the Company has the option to guarantee its allocated share of the securitization exchange bonds, which may then be offered and\n",
       "sold in the capital markets.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001273813_10-K_2020_section_8_313</td><td>0001273813_10-K_2020</td><td>0001273813</td></tr><tr class=''><td>Merck & Co., Inc.</td><td>MRK</td><td>8 (MD&A)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>Growth in these areas was largely offset by the effects of generic and biosimilar competition that resulted in declines for products such as Remicade\n",
       "and Nasonex.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000310158_10-K_2016_section_7_21</td><td>0000310158_10-K_2016</td><td>0000310158</td></tr><tr class=''><td>LAM RESEARCH CORP</td><td>LRCX</td><td>1 (Risk)</td><td>2015</td><td>2015-06-28</td><td class='sentence-cell'>The number of shares of our Common Stock into which the Convertible Notes are convertible for and the related warrants are exercisable for may be\n",
       "adjusted from time to time, including increases in such rates as a result of dividends that we pay to our stockholders.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000707549_10-K_2015_section_1A_47</td><td>0000707549_10-K_2015</td><td>0000707549</td></tr><tr class='kpi-true'><td>MICRON TECHNOLOGY INC</td><td>MU</td><td>10 (Notes)</td><td>2019</td><td>2019-08-29</td><td class='sentence-cell'>Under the terms of the credit agreement, we must maintain ratios, calculated as of the last day of each fiscal quarter, of total indebtedness to\n",
       "adjusted EBITDA not to exceed 2.75 to 1.00 and adjusted EBITDA to net interest expense of not less than 3.50 to 1.00.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000723125_10-K_2019_section_8_235</td><td>0000723125_10-K_2019</td><td>0000723125</td></tr><tr class=''><td>MBIA INC</td><td>MBI</td><td>10 (Notes)</td><td>2018</td><td>2018-12-31</td><td class='sentence-cell'>MBIA Inc. and Subsidiaries Notes to Consolidated Financial Statements Note 1: Business Developments and Risks and Uncertainties (continued) Risks and\n",
       "Uncertainties The Company’s financial statements include estimates and assumptions that affect the reported amounts of assets, liabilities, revenues\n",
       "and expenses.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0000814585_10-K_2018_section_8_51</td><td>0000814585_10-K_2018</td><td>0000814585</td></tr><tr class=''><td>HANOVER INSURANCE GROUP, INC.</td><td>THG</td><td>10 (Notes)</td><td>2018</td><td>2018-12-31</td><td class='sentence-cell'>Additionally, the Company may obtain non-binding broker quotes which are reported as Level 3.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000944695_10-K_2018_section_8_471</td><td>0000944695_10-K_2018</td><td>0000944695</td></tr><tr class='kpi-true'><td>MBIA INC</td><td>MBI</td><td>8 (MD&A)</td><td>2008</td><td>2008-12-31</td><td class='sentence-cell'>The following table presents the fair values of assets and liabilities recorded on our balance sheet that are classified as Level 3 within the fair\n",
       "value hierarchy, along with a brief description of the valuation technique for each type of asset and liability: Level 3 assets were $3.8 billion as\n",
       "of December 31, 2008, and represented approximately 21% of total assets measured at fair value.</td><td class='flag-true'>✓</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000814585_10-K_2008_section_7_424</td><td>0000814585_10-K_2008</td><td>0000814585</td></tr><tr class='kpi-true'><td>OGE ENERGY CORP.</td><td>OGE</td><td>10 (Notes)</td><td>2017</td><td>2017-12-31</td><td class='sentence-cell'>SPP Purchases and Sales OG&E currently owns and operates transmission and generation facilities as part of a vertically integrated utility.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001021635_10-K_2017_section_8_147</td><td>0001021635_10-K_2017</td><td>0001021635</td></tr><tr class=''><td>RADIAN GROUP INC</td><td>RDN</td><td>10 (Notes)</td><td>2018</td><td>2018-12-31</td><td class='sentence-cell'>Glossary Radian Group Inc. Notes to Consolidated Financial Statements (Continued)\n",
       "______________________________________________________________________________________________________ Radian Guaranty receives a 25% ceding\n",
       "commission for premiums ceded pursuant to this transaction.</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000890926_10-K_2018_section_8_708</td><td>0000890926_10-K_2018</td><td>0000890926</td></tr><tr class=''><td>CATERPILLAR INC</td><td>CAT</td><td>10 (Notes)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>The Committee approves all individual Officer grants.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000018230_10-K_2016_section_8_280</td><td>0000018230_10-K_2016</td><td>0000018230</td></tr><tr class='kpi-true'><td>FIRST BANCORP /PR/</td><td>FBP</td><td>10 (Notes)</td><td>2020</td><td>2020-12-31</td><td class='sentence-cell'>Commercial and Industrial - Commercial and Industrial (“C&I”) loans include both unsecured and secured loans for which the primary source of repayment\n",
       "comes from the ongoing operations and activities conducted by the borrower and not from rental income or the sale or refinancing of any underlying\n",
       "real estate collateral; thus, credit risk is largely dependent on the commercial borrower’s current and expected financial condition.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0001057706_10-K_2020_section_8_307</td><td>0001057706_10-K_2020</td><td>0001057706</td></tr><tr class='kpi-true'><td>IDACORP INC</td><td>IDA</td><td>8 (MD&A)</td><td>2018</td><td>2018-12-31</td><td class='sentence-cell'>The Idaho and Oregon power cost adjustment mechanisms mitigate in large part the potential adverse impacts of fluctuations in power supply costs to\n",
       "Idaho Power.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001057877_10-K_2018_section_7_81</td><td>0001057877_10-K_2018</td><td>0001057877</td></tr><tr class=''><td>Booking Holdings Inc.</td><td>BKNG</td><td>19 (Exhibits)</td><td>2017</td><td>2017-12-31</td><td class='sentence-cell'>The 2023 Notes were issued with an initial discount of $0.7 million.</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001075531_10-K_2017_section_15_516</td><td>0001075531_10-K_2017</td><td>0001075531</td></tr><tr class='kpi-true'><td>FLAGSTAR BANCORP INC</td><td>FBC</td><td>10 (Notes)</td><td>2019</td><td>2019-12-31</td><td class='sentence-cell'>If a previously hedged item is extinguished or sold, the remaining basis adjustment of the hedged item for prior fair value hedges will be\n",
       "reclassified to current period earnings.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0001033012_10-K_2019_section_8_250</td><td>0001033012_10-K_2019</td><td>0001033012</td></tr><tr class=''><td>MICROSOFT CORP</td><td>MSFT</td><td>8 (MD&A)</td><td>2011</td><td>2011-06-30</td><td class='sentence-cell'>These rich media experiences include games, movies, music, television, and social interactions with family, friends, and colleagues.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000789019_10-K_2011_section_7_26</td><td>0000789019_10-K_2011</td><td>0000789019</td></tr><tr class=''><td>GOODYEAR TIRE & RUBBER CO /OH/</td><td>GT</td><td>10 (Notes)</td><td>2007</td><td>2007-12-31</td><td class='sentence-cell'>Due to the creditworthiness of the counterparties, we consider the risk of counterparty nonperformance associated with these contracts to be remote.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000042582_10-K_2007_section_8_461</td><td>0000042582_10-K_2007</td><td>0000042582</td></tr><tr class=''><td>AbbVie Inc.</td><td>ABBV</td><td>8 (MD&A)</td><td>2016</td><td>2016-12-31</td><td class='sentence-cell'>The projected interest payments only pertain to obligations and agreements outstanding at December 31, 2016.</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td>0001551152_10-K_2016_section_7_265</td><td>0001551152_10-K_2016</td><td>0001551152</td></tr><tr class='kpi-true'><td>CATERPILLAR INC</td><td>CAT</td><td>1 (Risk)</td><td>2015</td><td>2015-12-31</td><td class='sentence-cell'>The risks associated with our past or future acquisitions also include the following: • the business culture of the acquired business may not match\n",
       "well with our culture; • technological and product synergies, economies of scale and cost reductions may not occur as expected; • unforeseen expenses,\n",
       "delays or conditions may be imposed upon the acquisition, including due to required regulatory approvals or consents; • we may acquire or assume\n",
       "unexpected liabilities or be subject to unexpected penalties or other enforcement actions; • faulty assumptions may be made regarding the integration\n",
       "process; • unforeseen difficulties may arise in integrating operations, processes and systems; • higher than expected investments may be required to\n",
       "implement necessary compliance processes and related systems, including IT systems, accounting systems and internal controls over financial reporting;\n",
       "• we may fail to retain, motivate and integrate key management and other employees of the acquired business; • higher than expected costs may arise\n",
       "due to unforeseen changes in tax, trade, environmental, labor, safety, payroll or pension policies in any jurisdiction in which the acquired business\n",
       "conducts its operations; and • we may experience problems in retaining customers and integrating customer bases.</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td class='flag-true'>✓</td><td>0000018230_10-K_2015_section_1A_110</td><td>0000018230_10-K_2015</td><td>0000018230</td></tr><tr class=''><td>QUALCOMM INC/DE</td><td>QCOM</td><td>8 (MD&A)</td><td>2018</td><td>2018-09-30</td><td class='sentence-cell'>Royalty revenues related to the products of Apple’s contract manufacturers and the other licensee in dispute were approximately $1.7 billion in fiscal\n",
       "2017.</td><td style='color:#555'>-</td><td class='flag-true'>✓</td><td style='color:#555'>-</td><td style='color:#555'>-</td><td>0000804328_10-K_2018_section_7_105</td><td>0000804328_10-K_2018</td><td>0000804328</td></tr>\n",
       "            </tbody>\n",
       "        </table>\n",
       "    </div>\n",
       "    <div class='metadata'>\n",
       "        Showing 100 of 100 rows | \n",
       "        13 columns displayed | \n",
       "        Random sample (refreshes each run)\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# inspect_sample_clean.py\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "import textwrap\n",
    "\n",
    "# Load data\n",
    "data_path = r\"D:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\finrag-insights-mlops\\data\\exports\\sec_finrag_1M_sample.parquet\"\n",
    "df = pl.read_parquet(data_path)\n",
    "\n",
    "# Random sample - no seed\n",
    "sample = df.sample(n=100)\n",
    "\n",
    "def display_business_view(df, max_rows=100, wrap_length=150, table_height=\"700px\"):\n",
    "    \"\"\"Display business-relevant columns with proper sentence wrapping\"\"\"\n",
    "    \n",
    "    # Select only business-relevant columns\n",
    "    business_cols = [\n",
    "        'name', 'tickers', 'section', 'report_year', 'reportDate',\n",
    "        'sentence',  # Main content\n",
    "        'likely_kpi', 'has_numbers', 'is_table_like', 'has_forward_looking',\n",
    "        'sentenceID', 'docID', 'cik'\n",
    "    ]\n",
    "    \n",
    "    # Filter to only columns that exist\n",
    "    display_cols = [col for col in business_cols if col in df.columns]\n",
    "    \n",
    "    html_content = f\"\"\"\n",
    "    <style>\n",
    "        .sentence-table {{\n",
    "            border-collapse: collapse;\n",
    "            width: 100%;\n",
    "            font-size: 12px;\n",
    "            font-family: 'Segoe UI', Tahoma, sans-serif;\n",
    "            background-color: #1e1e1e;\n",
    "            color: #d4d4d4;\n",
    "        }}\n",
    "        .sentence-table th {{\n",
    "            background-color: #2d2d30;\n",
    "            color: #4EC9B0;\n",
    "            padding: 10px;\n",
    "            text-align: left;\n",
    "            position: sticky;\n",
    "            top: 0;\n",
    "            z-index: 10;\n",
    "            border-bottom: 2px solid #007ACC;\n",
    "        }}\n",
    "        .sentence-table td {{\n",
    "            border: 1px solid #3a3a3a;\n",
    "            padding: 8px;\n",
    "            vertical-align: top;\n",
    "        }}\n",
    "        .sentence-table tr:hover {{\n",
    "            background-color: #2a2d2e;\n",
    "        }}\n",
    "        .sentence-cell {{\n",
    "            white-space: pre-wrap;\n",
    "            word-wrap: break-word;\n",
    "            max-width: 800px;\n",
    "            min-width: 400px;\n",
    "            line-height: 1.4;\n",
    "            font-family: 'Consolas', 'Courier New', monospace;\n",
    "        }}\n",
    "        .table-container {{\n",
    "            height: {table_height};\n",
    "            overflow: auto;\n",
    "            border: 1px solid #007ACC;\n",
    "        }}\n",
    "        .kpi-true {{\n",
    "            background-color: #2a3f2a !important;\n",
    "        }}\n",
    "        .flag-true {{\n",
    "            color: #4EC9B0;\n",
    "            font-weight: bold;\n",
    "        }}\n",
    "        .metadata {{\n",
    "            color: #808080;\n",
    "            font-size: 11px;\n",
    "            padding: 10px;\n",
    "            background-color: #1e1e1e;\n",
    "        }}\n",
    "    </style>\n",
    "    \n",
    "    <div class=\"table-container\">\n",
    "        <table class=\"sentence-table\">\n",
    "            <thead>\n",
    "                <tr>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add headers with better sizing\n",
    "    for col in display_cols:\n",
    "        if col == \"sentence\":\n",
    "            width = \"50%\"\n",
    "        elif col == \"name\":\n",
    "            width = \"10%\"\n",
    "        elif col in [\"likely_kpi\", \"has_numbers\"]:\n",
    "            width = \"5%\"\n",
    "        else:\n",
    "            width = \"auto\"\n",
    "        html_content += f\"<th style='width: {width}'>{col}</th>\"\n",
    "    html_content += \"</tr></thead><tbody>\"\n",
    "    \n",
    "    # Add data rows\n",
    "    for i, row in enumerate(df.head(max_rows).iter_rows(named=True)):\n",
    "        kpi_class = \"kpi-true\" if row.get('likely_kpi', False) else \"\"\n",
    "        html_content += f\"<tr class='{kpi_class}'>\"\n",
    "        \n",
    "        for col in display_cols:\n",
    "            value = row.get(col, \"\")\n",
    "            \n",
    "            if col == \"sentence\":\n",
    "                if isinstance(value, str):\n",
    "                    # Better wrapping for readability\n",
    "                    wrapped = textwrap.fill(value, width=wrap_length, \n",
    "                                          break_long_words=False,\n",
    "                                          break_on_hyphens=False)\n",
    "                    html_content += f\"<td class='sentence-cell'>{wrapped}</td>\"\n",
    "                else:\n",
    "                    html_content += f\"<td>{value}</td>\"\n",
    "                    \n",
    "            elif col in [\"likely_kpi\", \"has_numbers\", \"is_table_like\", \"has_forward_looking\"]:\n",
    "                if value:\n",
    "                    html_content += f\"<td class='flag-true'>✓</td>\"\n",
    "                else:\n",
    "                    html_content += f\"<td style='color:#555'>-</td>\"\n",
    "                    \n",
    "            elif col == \"section\":\n",
    "                section_map = {\n",
    "                    0: \"Business\", 1: \"Risk\", 7: \"MD&A(old)\", \n",
    "                    8: \"MD&A\", 9: \"FinStmt\", 10: \"Notes\", \n",
    "                    11: \"Controls\", 19: \"Exhibits\"\n",
    "                }\n",
    "                label = section_map.get(value, str(value))\n",
    "                html_content += f\"<td>{value} ({label})</td>\"\n",
    "                \n",
    "            elif col == \"tickers\":\n",
    "                # Handle list columns\n",
    "                if isinstance(value, list):\n",
    "                    html_content += f\"<td>{', '.join(value)}</td>\"\n",
    "                else:\n",
    "                    html_content += f\"<td>{value}</td>\"\n",
    "            else:\n",
    "                html_content += f\"<td>{value}</td>\"\n",
    "        \n",
    "        html_content += \"</tr>\"\n",
    "    \n",
    "    html_content += f\"\"\"\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </div>\n",
    "    <div class='metadata'>\n",
    "        Showing {min(max_rows, len(df))} of {len(df)} rows | \n",
    "        {len(display_cols)} columns displayed | \n",
    "        Random sample (refreshes each run)\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(html_content))\n",
    "\n",
    "# Display the sample\n",
    "print(f\"Sampled {len(sample)} random sentences from {len(df)} total\")\n",
    "print(f\"Key signals: {sample['likely_kpi'].sum()} likely KPIs, {sample['has_numbers'].sum()} with numbers\")\n",
    "display_business_view(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f255ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84024334",
   "metadata": {},
   "source": [
    "\n",
    "## KPI pipeline 1 QA extraction, transformers - pipeline, Roberta, BatchProcessor, etc.\n",
    "\n",
    "#### Move on from - RoBERTa \n",
    "1. RoBERTa is simple span extraction. \n",
    "2. FinBERT is 110MB - much smaller than RoBERTa-squad2. But critically, FinBERT is trained for sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56841089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 05:01:21,943 - INFO - ============================================================\n",
      "2025-10-21 05:01:21,944 - INFO - RUNNING QUICK TEST\n",
      "2025-10-21 05:01:21,945 - INFO - ============================================================\n",
      "2025-10-21 05:01:21,946 - INFO - CUDA is available\n",
      "2025-10-21 05:01:21,948 - INFO - GPU Device: NVIDIA GeForce RTX 3080 Ti Laptop GPU\n",
      "2025-10-21 05:01:21,949 - INFO - GPU Memory: 17.18 GB\n",
      "2025-10-21 05:01:21,949 - INFO - Loading model: deepset/roberta-base-squad2\n",
      "Device set to use cuda:0\n",
      "2025-10-21 05:01:24,292 - INFO - Model loaded successfully in 2.3s\n",
      "2025-10-21 05:01:24,293 - INFO - BatchProcessor initialized with batch_size=16\n",
      "2025-10-21 05:01:24,294 - INFO - Testing pipeline with sample...\n",
      "2025-10-21 05:01:24,315 - INFO - Test successful: {'score': 0.0006287800497375429, 'start': 16, 'end': 28, 'answer': '$100 million'}\n",
      "2025-10-21 05:01:24,316 - INFO - Loading data from D:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\finrag-insights-mlops\\data\\exports\\sec_finrag_1M_sample.parquet\n",
      "2025-10-21 05:01:24,318 - INFO - Random sampling 1000 rows\n",
      "2025-10-21 05:01:24,753 - INFO - Data loaded in 0.0s\n",
      "2025-10-21 05:01:24,754 - INFO - Processing 1000 sentences\n",
      "2025-10-21 05:01:24,756 - INFO - Section distribution in sample:\n",
      "2025-10-21 05:01:24,757 - INFO -   Section 10: 340 sentences\n",
      "2025-10-21 05:01:24,758 - INFO -   Section 8: 231 sentences\n",
      "2025-10-21 05:01:24,758 - INFO -   Section 1: 159 sentences\n",
      "2025-10-21 05:01:24,759 - INFO -   Section 0: 95 sentences\n",
      "2025-10-21 05:01:24,759 - INFO -   Section 19: 87 sentences\n",
      "Processing batches:  40%|███▉      | 25/63 [00:08<00:16,  2.33it/s]2025-10-21 05:01:34,152 - INFO - \n",
      "--- Progress at sentence 400/1000 ---\n",
      "2025-10-21 05:01:34,153 - INFO - KPIs found so far: 72\n",
      "2025-10-21 05:01:34,154 - INFO - Latest KPI: financial_metric = $2.6 million\n",
      "2025-10-21 05:01:34,156 - INFO - From: The CPUC also authorized GSWC to track the remaining $2.6 million in a memorandum account....\n",
      "2025-10-21 05:01:34,158 - INFO - Confidence: 0.000\n",
      "Processing batches:  79%|███████▉  | 50/63 [00:21<00:06,  1.88it/s]2025-10-21 05:01:47,040 - INFO - \n",
      "--- Progress at sentence 800/1000 ---\n",
      "2025-10-21 05:01:47,041 - INFO - KPIs found so far: 151\n",
      "2025-10-21 05:01:47,042 - INFO - Latest KPI: revenue = $134 million\n",
      "2025-10-21 05:01:47,042 - INFO - From: RM&T segment revenues increased $134 million in 2007 from 2006 and decreased $62 million in 2006 fro...\n",
      "2025-10-21 05:01:47,043 - INFO - Confidence: 0.015\n",
      "Processing batches: 100%|██████████| 63/63 [00:32<00:00,  1.92it/s]\n",
      "2025-10-21 05:01:57,656 - INFO - \n",
      "Extraction complete. Found 189 total KPI mentions\n",
      "2025-10-21 05:01:57,658 - INFO - After deduplication: 149 unique KPIs\n",
      "2025-10-21 05:01:57,685 - INFO - \n",
      "Results Summary:\n",
      "2025-10-21 05:01:57,686 - INFO - - Extracted 149 KPIs in 33.4s\n",
      "2025-10-21 05:01:57,691 - INFO - - Columns: ['kpi_type', 'value', 'value_raw', 'year', 'confidence', 'source_answer', 'original_sentence', 'sentenceID', 'cik', 'ticker', 'company', 'section', 'docID', 'reportDate']\n",
      "2025-10-21 05:01:57,693 - INFO - ✓ sentenceID preserved for accuracy testing\n",
      "2025-10-21 05:01:57,703 - INFO - Saved full results to: extracted_kpis_test.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Business View - Top 10 KPIs:\n",
      "shape: (10, 8)\n",
      "┌────────────────┬───────────┬───────────────┬──────────┬──────┬─────────┬────────────┬────────────┐\n",
      "│ company        ┆ ticker    ┆ kpi_type      ┆ value    ┆ year ┆ section ┆ reportDate ┆ confidence │\n",
      "│ ---            ┆ ---       ┆ ---           ┆ ---      ┆ ---  ┆ ---     ┆ ---        ┆ ---        │\n",
      "│ str            ┆ list[str] ┆ str           ┆ f64      ┆ str  ┆ i64     ┆ str        ┆ f64        │\n",
      "╞════════════════╪═══════════╪═══════════════╪══════════╪══════╪═════════╪════════════╪════════════╡\n",
      "│ GENWORTH       ┆ [\"GNW\"]   ┆ financial_met ┆ 2.76e8   ┆ 2011 ┆ 8       ┆ 2011-12-31 ┆ 0.000004   │\n",
      "│ FINANCIAL INC  ┆           ┆ ric           ┆          ┆      ┆         ┆            ┆            │\n",
      "│ PNM RESOURCES  ┆ [\"PNM\"]   ┆ financial_met ┆ 8.2000e6 ┆ 20   ┆ 10      ┆ 2013-12-31 ┆ 0.000807   │\n",
      "│ INC            ┆           ┆ ric           ┆          ┆      ┆         ┆            ┆            │\n",
      "│ QUALCOMM       ┆ [\"QCOM\"]  ┆ financial_met ┆ 8.04e8   ┆ 2018 ┆ 19      ┆ 2018-09-30 ┆ 0.000019   │\n",
      "│ INC/DE         ┆           ┆ ric           ┆          ┆      ┆         ┆            ┆            │\n",
      "│ RADIAN GROUP   ┆ [\"RDN\"]   ┆ financial_met ┆ 2e8      ┆ 2019 ┆ 6       ┆ 2019-12-31 ┆ 0.000001   │\n",
      "│ INC            ┆           ┆ ric           ┆          ┆      ┆         ┆            ┆            │\n",
      "│ BOEING CO      ┆ [\"BA\"]    ┆ income        ┆ 2.55e8   ┆ 2016 ┆ 8       ┆ 2016-12-31 ┆ 0.043718   │\n",
      "│ THERMO FISHER  ┆ [\"TMO\"]   ┆ financial_met ┆ 1.46e7   ┆ 20   ┆ 19      ┆ 2016-12-31 ┆ 0.000001   │\n",
      "│ SCIENTIFIC     ┆           ┆ ric           ┆          ┆      ┆         ┆            ┆            │\n",
      "│ INC.           ┆           ┆               ┆          ┆      ┆         ┆            ┆            │\n",
      "│ Booking        ┆ [\"BKNG\"]  ┆ financial_met ┆ 5.09e8   ┆ 20   ┆ 0       ┆ 2018-12-31 ┆ 0.000014   │\n",
      "│ Holdings Inc.  ┆           ┆ ric           ┆          ┆      ┆         ┆            ┆            │\n",
      "│ HANOVER        ┆ [\"THG\"]   ┆ financial_met ┆ 1.7e8    ┆ 2016 ┆ 10      ┆ 2016-12-31 ┆ 0.000479   │\n",
      "│ INSURANCE      ┆           ┆ ric           ┆          ┆      ┆         ┆            ┆            │\n",
      "│ GROUP, INC.    ┆           ┆               ┆          ┆      ┆         ┆            ┆            │\n",
      "│ BOEING CO      ┆ [\"BA\"]    ┆ financial_met ┆ 2.0000e9 ┆ 20   ┆ 8       ┆ 2008-12-31 ┆ 0.000099   │\n",
      "│                ┆           ┆ ric           ┆          ┆      ┆         ┆            ┆            │\n",
      "│ CNX Resources  ┆ [\"CNX\"]   ┆ financial_met ┆ 2e6      ┆ 2013 ┆ 8       ┆ 2013-12-31 ┆ 0.000032   │\n",
      "│ Corp           ┆           ┆ ric           ┆          ┆      ┆         ┆            ┆            │\n",
      "└────────────────┴───────────┴───────────────┴──────────┴──────┴─────────┴────────────┴────────────┘\n",
      "\n",
      "KPI Type Distribution:\n",
      "shape: (6, 2)\n",
      "┌──────────────────┬───────┐\n",
      "│ kpi_type         ┆ count │\n",
      "│ ---              ┆ ---   │\n",
      "│ str              ┆ u32   │\n",
      "╞══════════════════╪═══════╡\n",
      "│ financial_metric ┆ 88    │\n",
      "│ net_income       ┆ 25    │\n",
      "│ revenue          ┆ 17    │\n",
      "│ income           ┆ 15    │\n",
      "│ eps              ┆ 2     │\n",
      "│ margin           ┆ 2     │\n",
      "└──────────────────┴───────┘\n",
      "\n",
      "Confidence Stats:\n",
      "  Mean: 0.003\n",
      "  Min: 0.000\n",
      "  Max: 0.063\n"
     ]
    }
   ],
   "source": [
    "# kpi_extraction_pipeline_v2.py - Fixed version with diagnostics\n",
    "import polars as pl\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import re\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ============= Configuration =============\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration for KPI extraction pipeline\"\"\"\n",
    "    data_path: str = r\"D:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\finrag-insights-mlops\\data\\exports\\sec_finrag_1M_sample.parquet\"\n",
    "    \n",
    "    model_name: str = \"deepset/roberta-base-squad2\"\n",
    "    \n",
    "    batch_size: int = 32\n",
    "    confidence_threshold: float = 0.0\n",
    "    device: int = 0 if torch.cuda.is_available() else -1\n",
    "    max_answer_length: int = 100\n",
    "    output_path: str = \"extracted_kpis.parquet\"\n",
    "    sample_size: Optional[int] = 5000  \n",
    "\n",
    "# ============= KPI Parser (unchanged) =============\n",
    "class KPIParser:\n",
    "    \"\"\"Parses QA model answers into structured KPI records\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.patterns = {\n",
    "            'currency_value': re.compile(r'\\$?([\\d,]+(?:\\.\\d+)?)\\s*(?:billion|million|B|M|bn|mn)', re.I),\n",
    "            'percentage': re.compile(r'([\\d,]+(?:\\.\\d+)?)\\s*%'),\n",
    "            'year': re.compile(r'\\b(19|20)\\d{2}\\b'),\n",
    "            'quarter': re.compile(r'\\b(Q[1-4])\\s*(?:19|20)?\\d{2}\\b', re.I),\n",
    "        }\n",
    "        \n",
    "\n",
    "\n",
    "    def parse_answer(self, answer_text: str, original_sentence: str, metadata: Dict) -> List[Dict]:\n",
    "        \"\"\"Parse QA answer into structured KPIs\"\"\"\n",
    "        kpis = []\n",
    "        \n",
    "        for match in self.patterns['currency_value'].finditer(answer_text):\n",
    "            value_str = match.group(1).replace(',', '')\n",
    "            \n",
    "            # FIX: Check for empty string BEFORE trying to convert to float\n",
    "            if not value_str or value_str.strip() == '':\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                value = float(value_str)\n",
    "            except ValueError:\n",
    "                continue  # Skip if still can't convert\n",
    "            \n",
    "            unit = match.group(0).split()[-1].upper()\n",
    "            \n",
    "            if unit in ['BILLION', 'BN', 'B']:\n",
    "                multiplier = 1e9\n",
    "            elif unit in ['MILLION', 'MN', 'M']:\n",
    "                multiplier = 1e6\n",
    "            else:\n",
    "                multiplier = 1\n",
    "            \n",
    "            value = value * multiplier\n",
    "            \n",
    "            year = None\n",
    "            year_matches = self.patterns['year'].findall(answer_text)\n",
    "            if year_matches:\n",
    "                year = year_matches[0]\n",
    "            \n",
    "            kpi_type = self._infer_kpi_type(answer_text, original_sentence)\n",
    "            \n",
    "            kpis.append({\n",
    "                'kpi_type': kpi_type,\n",
    "                'value': value,\n",
    "                'value_raw': match.group(0),\n",
    "                'year': year or metadata.get('reportDate', '')[:4] if metadata.get('reportDate') else '',\n",
    "                'confidence': metadata.get('confidence', 0.5),\n",
    "                'source_answer': answer_text[:200],\n",
    "                'original_sentence': original_sentence[:300],\n",
    "                'sentenceID': metadata.get('sentenceID', ''),\n",
    "                'cik': metadata.get('cik', ''),\n",
    "                'ticker': metadata.get('ticker', ''),\n",
    "                'company': metadata.get('company', ''),\n",
    "                'section': metadata.get('section', ''),\n",
    "                'docID': metadata.get('docID', ''),\n",
    "                'reportDate': metadata.get('reportDate', '')  # ADD THIS for business context\n",
    "            })\n",
    "        \n",
    "        return kpis\n",
    "\n",
    "\n",
    "\n",
    "    def _infer_kpi_type(self, answer_text: str, original_sentence: str) -> str:\n",
    "        \"\"\"Infer KPI type from context\"\"\"\n",
    "        context = (answer_text + \" \" + original_sentence).lower()\n",
    "        \n",
    "        if any(term in context for term in ['revenue', 'sales', 'turnover']):\n",
    "            return 'revenue'\n",
    "        elif any(term in context for term in ['income', 'earnings', 'profit']):\n",
    "            return 'net_income' if 'net' in context else 'operating_income' if 'operating' in context else 'income'\n",
    "        elif 'ebitda' in context:\n",
    "            return 'ebitda'\n",
    "        elif 'margin' in context:\n",
    "            return 'gross_margin' if 'gross' in context else 'operating_margin' if 'operating' in context else 'margin'\n",
    "        elif any(term in context for term in ['eps', 'per share']):\n",
    "            return 'eps'\n",
    "        else:\n",
    "            return 'financial_metric'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============= Batch Processor with Better Logging =============\n",
    "class BatchProcessor:\n",
    "    \"\"\"Handles efficient batch processing for GPU\"\"\"\n",
    "    \n",
    "    def __init__(self, qa_pipeline, batch_size: int = 8, confidence_threshold: float = 0.0):\n",
    "        self.qa_pipeline = qa_pipeline\n",
    "        self.batch_size = batch_size\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.parser = KPIParser()\n",
    "        logger.info(f\"BatchProcessor initialized with batch_size={batch_size}\")\n",
    "    \n",
    "    def process_batch(self, sentences: List[str], metadata_list: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Process a batch of sentences through QA pipeline\"\"\"\n",
    "        all_kpis = []\n",
    "        \n",
    "        # questions for speed; increase later\n",
    "        questions = [\n",
    "            \"What are the financial metrics, values, and years mentioned?\",\n",
    "            \"What revenue or earnings figures are reported?\"\n",
    "        ]\n",
    "        \n",
    "        logger.debug(f\"Processing batch of {len(sentences)} sentences\")\n",
    "        \n",
    "        for q_idx, question in enumerate(questions):\n",
    "            try:\n",
    "                qa_inputs = [\n",
    "                    {\"question\": question, \"context\": sentence}\n",
    "                    for sentence in sentences\n",
    "                ]\n",
    "                \n",
    "                # TIME THE PIPELINE CALL\n",
    "                start = time.time()\n",
    "                answers = self.qa_pipeline(qa_inputs)\n",
    "                logger.debug(f\"Question {q_idx+1} processed in {time.time()-start:.2f}s\")\n",
    "\n",
    "                ## during exploration, capture everything and analyze the confidence distribution later ??\n",
    "                for answer, sentence, metadata in zip(answers, sentences, metadata_list):\n",
    "                    if answer['score'] >= Config.confidence_threshold:\n",
    "                        metadata['confidence'] = answer['score']\n",
    "                        kpis = self.parser.parse_answer(\n",
    "                            answer['answer'],\n",
    "                            sentence,\n",
    "                            metadata\n",
    "                        )\n",
    "                        all_kpis.extend(kpis)\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Batch processing error: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return all_kpis\n",
    "\n",
    "# ============= Main KPI Extractor with Diagnostics =============\n",
    "class KPIExtractor:\n",
    "    \"\"\"Main orchestrator for KPI extraction pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        \n",
    "        # BETTER DEVICE LOGGING\n",
    "        if torch.cuda.is_available():\n",
    "            logger.info(f\"CUDA is available\")\n",
    "            logger.info(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "            logger.info(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        else:\n",
    "            logger.warning(\"CUDA not available, using CPU\")\n",
    "        \n",
    "        logger.info(f\"Loading model: {config.model_name}\")\n",
    "        \n",
    "        # TIME MODEL LOADING\n",
    "        start = time.time()\n",
    "        try:\n",
    "            self.qa_pipeline = pipeline(\n",
    "                \"question-answering\",\n",
    "                model=config.model_name,\n",
    "                device=config.device,\n",
    "                max_answer_len=config.max_answer_length\n",
    "            )\n",
    "            logger.info(f\"Model loaded successfully in {time.time()-start:.1f}s\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load model: {e}\")\n",
    "            raise\n",
    "\n",
    "        self.batch_processor = BatchProcessor(self.qa_pipeline, config.batch_size, config.confidence_threshold)\n",
    "\n",
    "        ## self.numeric_pattern = re.compile(r'\\d+\\.?\\d*[BMK%]?|\\$\\d+')\n",
    "        \n",
    "        # TEST THE PIPELINE\n",
    "        logger.info(\"Testing pipeline with sample...\")\n",
    "        test_result = self.qa_pipeline(\n",
    "            question=\"What is the revenue?\", \n",
    "            context=\"The revenue was $100 million in 2020\"\n",
    "        )\n",
    "        logger.info(f\"Test successful: {test_result}\")\n",
    "    \n",
    "\n",
    "\n",
    "    def extract_from_dataset(self, show_diagnostics: bool = True, diagnostic_interval: int = 200) -> pl.DataFrame:\n",
    "        \"\"\"Main extraction pipeline - NO PRE-FILTERING\n",
    "        \n",
    "        Args:\n",
    "            show_diagnostics: Whether to show progress examples during processing\n",
    "            diagnostic_interval: Show example every N sentences (only if show_diagnostics=True)\n",
    "        \"\"\"\n",
    "        logger.info(f\"Loading data from {self.config.data_path}\")\n",
    "        \n",
    "        # Load data\n",
    "        df_lazy = pl.scan_parquet(self.config.data_path)\n",
    "        \n",
    "        if self.config.sample_size:\n",
    "            logger.info(f\"Random sampling {self.config.sample_size} rows\")\n",
    "            df_full = df_lazy.collect()\n",
    "            df = df_full.sample(n=min(self.config.sample_size, len(df_full)), seed=42)\n",
    "        else:\n",
    "            df = df_lazy.collect()\n",
    "        \n",
    "        # Select needed columns\n",
    "        start = time.time()\n",
    "        df = df.select([\n",
    "            \"sentence\", \"tickers\", \"name\", \"section\", \n",
    "            \"reportDate\", \"cik\", \"sentenceID\", \"docID\"\n",
    "        ])\n",
    "        logger.info(f\"Data loaded in {time.time()-start:.1f}s\")\n",
    "        logger.info(f\"Processing {len(df)} sentences\")\n",
    "        \n",
    "        # Show data distribution only if diagnostics enabled\n",
    "        if show_diagnostics:\n",
    "            section_counts = df.group_by(\"section\").count().sort(\"count\", descending=True)\n",
    "            logger.info(\"Section distribution in sample:\")\n",
    "            for row in section_counts.head(5).iter_rows(named=True):\n",
    "                logger.info(f\"  Section {row['section']}: {row['count']} sentences\")\n",
    "        \n",
    "        # Process everything\n",
    "        all_kpis = []\n",
    "        sentences = df[\"sentence\"].to_list()\n",
    "        \n",
    "        # Metadata mapping\n",
    "        metadata_list = []\n",
    "        for row in df.iter_rows(named=True):\n",
    "            metadata_list.append({\n",
    "                'ticker': row['tickers'],\n",
    "                'company': row['name'],\n",
    "                'section': row['section'],\n",
    "                'reportDate': str(row['reportDate']) if row['reportDate'] else '',\n",
    "                'cik': row['cik'],\n",
    "                'sentenceID': row['sentenceID'],\n",
    "                'docID': row['docID']\n",
    "            })\n",
    "        \n",
    "        # Process batches\n",
    "        for i in tqdm(range(0, len(sentences), self.config.batch_size), desc=\"Processing batches\"):\n",
    "            batch_sentences = sentences[i:i + self.config.batch_size]\n",
    "            batch_metadata = metadata_list[i:i + self.config.batch_size]\n",
    "            \n",
    "            kpis = self.batch_processor.process_batch(\n",
    "                batch_sentences,\n",
    "                batch_metadata\n",
    "            )\n",
    "            all_kpis.extend(kpis)\n",
    "            \n",
    "            # Diagnostic output only if enabled\n",
    "            if show_diagnostics and i > 0 and i % diagnostic_interval == 0:\n",
    "                logger.info(f\"\\n--- Progress at sentence {i}/{len(sentences)} ---\")\n",
    "                logger.info(f\"KPIs found so far: {len(all_kpis)}\")\n",
    "                if all_kpis:\n",
    "                    latest = all_kpis[-1]\n",
    "                    logger.info(f\"Latest KPI: {latest['kpi_type']} = {latest['value_raw']}\")\n",
    "                    logger.info(f\"From: {latest['original_sentence'][:100]}...\")\n",
    "                    logger.info(f\"Confidence: {latest['confidence']:.3f}\")\n",
    "        \n",
    "        logger.info(f\"\\nExtraction complete. Found {len(all_kpis)} total KPI mentions\")\n",
    "        \n",
    "        if all_kpis:\n",
    "            kpi_df = pl.DataFrame(all_kpis)\n",
    "            kpi_df = kpi_df.unique(subset=['kpi_type', 'value', 'year', 'ticker', 'sentenceID'])\n",
    "            logger.info(f\"After deduplication: {len(kpi_df)} unique KPIs\")\n",
    "            return kpi_df\n",
    "        else:\n",
    "            return pl.DataFrame()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# ============= Quick Test Function =============\n",
    "def quick_test():\n",
    "    \"\"\"Quick test with minimal data\"\"\"\n",
    "    config = Config()\n",
    "    config.sample_size = 1000  \n",
    "    config.batch_size = 16     \n",
    "    \n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(\"RUNNING QUICK TEST\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    extractor = KPIExtractor(config)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    kpi_df = extractor.extract_from_dataset(show_diagnostics=True, diagnostic_interval=200)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    if kpi_df is not None and len(kpi_df) > 0:\n",
    "        logger.info(f\"\\nResults Summary:\")\n",
    "        logger.info(f\"- Extracted {len(kpi_df)} KPIs in {elapsed:.1f}s\")\n",
    "        logger.info(f\"- Columns: {kpi_df.columns}\")\n",
    "        \n",
    "        # Enhanced business view - just select more columns we already have\n",
    "        if 'sentenceID' in kpi_df.columns:\n",
    "            logger.info(\"✓ sentenceID preserved for accuracy testing\")\n",
    "            \n",
    "            # Better sample with business context\n",
    "            business_sample = kpi_df.select([\n",
    "                'company', 'ticker', 'kpi_type', 'value', \n",
    "                'year', 'section', 'reportDate', 'confidence'\n",
    "            ]).head(10)\n",
    "            \n",
    "            print(\"\\nBusiness View - Top 10 KPIs:\")\n",
    "            print(business_sample)\n",
    "            \n",
    "            # Group by KPI type to show distribution\n",
    "            kpi_distribution = kpi_df.group_by('kpi_type').count().sort('count', descending=True)\n",
    "            print(\"\\nKPI Type Distribution:\")\n",
    "            print(kpi_distribution)\n",
    "            \n",
    "            # Show confidence stats\n",
    "            print(f\"\\nConfidence Stats:\")\n",
    "            print(f\"  Mean: {kpi_df['confidence'].mean():.3f}\")\n",
    "            print(f\"  Min: {kpi_df['confidence'].min():.3f}\")\n",
    "            print(f\"  Max: {kpi_df['confidence'].max():.3f}\")\n",
    "            \n",
    "            # Save with all columns -- some errors around sink csv issue.\n",
    "            # kpi_df.write_csv(\"extracted_kpis_test.csv\")\n",
    "            logger.info(f\"Saved full results to: extracted_kpis_test.csv\")\n",
    "        \n",
    "        return kpi_df\n",
    "    else:\n",
    "        logger.warning(\"No KPIs extracted\")\n",
    "        return pl.DataFrame()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Run the test\n",
    "if __name__ == \"__main__\":\n",
    "    kpi_results = quick_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0fb672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9b621cd",
   "metadata": {},
   "source": [
    "#### yes—\n",
    "- on KPI-style extraction from 10-K/10-Q text, modern LLMs (e.g., Qwen2.5, DeepSeek-V3, Mixtral) beat BERT-class models like FinBERT/ProBERT on entity/value/date/currency labeling and structured JSON extraction.\n",
    "- newer LLMs do multi-entity span reasoning + format-following much better\n",
    "- MoE/large dense models generalize across wildly varied KPI phrasings\n",
    "\n",
    "\n",
    "#### previous work:\n",
    "```\n",
    "batch = [\"sentence1\", \"sentence2\", \"sentence3\", ..., \"sentence16\"]\n",
    "results = qa_pipeline(batch)  # All 16 processed in parallel on GPU\n",
    "```\n",
    "- Transformers library and PyTorch handle this parallelization automatically.\n",
    "- Sad, Qwen-14B fills most of 16GB VRAM, Ollama runs as a REST server handling one request at a time.\n",
    "- Each generation needs additional memory for KV cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d8e54",
   "metadata": {},
   "source": [
    "### KPI pipeline 2 attempt: Tried 14b param model. V slow.\n",
    "#### ----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e906100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 06:01:12,192 - INFO - Initialized ollama backend\n",
      "2025-10-21 06:01:12,193 - INFO - Loading data from D:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\finrag-insights-mlops\\data\\exports\\sec_finrag_1M_sample.parquet\n",
      "2025-10-21 06:01:12,538 - INFO - Random sampling 100 from 1003534 rows\n",
      "2025-10-21 06:01:12,616 - INFO - Dataset ready: 100 sentences\n",
      "2025-10-21 06:01:12,616 - INFO - Section distribution:\n",
      "2025-10-21 06:01:12,624 - INFO -   Section 10: 37\n",
      "2025-10-21 06:01:12,624 - INFO -   Section 1: 25\n",
      "2025-10-21 06:01:12,624 - INFO -   Section 8: 15\n",
      "2025-10-21 06:01:12,624 - INFO -   Section 19: 14\n",
      "2025-10-21 06:01:12,624 - INFO -   Section 0: 4\n",
      "Extracting KPIs: 100%|██████████| 100/100 [14:36<00:00,  8.77s/it]\n",
      "2025-10-21 06:15:49,311 - WARNING - No KPIs extracted\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "import time\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Any, Union\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ============= Configuration =============\n",
    "@dataclass\n",
    "class ExtractionConfig:\n",
    "    \"\"\"Configuration for KPI extraction pipeline\"\"\"\n",
    "    data_path: str\n",
    "    output_dir: str = \"./kpi_outputs\"\n",
    "    sample_size: Optional[int] = None  # None = full dataset\n",
    "    random_seed: int = 42\n",
    "    checkpoint_interval: int = 1000\n",
    "    backend: str = \"ollama\"  # ollama, transformers, anthropic, openai\n",
    "    model_name: str = \"qwen2.5:14b-instruct-q4_K_M\"\n",
    "    temperature: float = 0.0\n",
    "    max_retries: int = 2\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        Path(self.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ============= Abstract Base Extractor =============\n",
    "class BaseKPIExtractor(ABC):\n",
    "    \"\"\"Abstract base class for different extraction backends\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def extract(self, text: str, metadata: Dict[str, Any]) -> List[Dict]:\n",
    "        \"\"\"Extract KPIs from text\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def health_check(self) -> bool:\n",
    "        \"\"\"Check if backend is available\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_prompt(self, text: str, metadata: Dict[str, Any]) -> str:\n",
    "        \"\"\"Common prompt template across backends\"\"\"\n",
    "        return f\"\"\"Extract ALL financial KPIs from this text. Return ONLY valid JSON array.\n",
    "\n",
    "Text: {text}\n",
    "Company: {metadata.get('company', 'Unknown')}\n",
    "Section: {metadata.get('section', '')}\n",
    "Report Date: {metadata.get('reportDate', '')}\n",
    "\n",
    "For each KPI found, include:\n",
    "- metric_type: revenue|earnings|margin|debt|cash_flow|capex|operational|other\n",
    "- value: numeric value (no commas)\n",
    "- unit: millions|billions|percent|ratio|count\n",
    "- year: YYYY or null\n",
    "- quarter: Q1|Q2|Q3|Q4 or null\n",
    "- confidence: 0.0-1.0\n",
    "- explanation: brief context\n",
    "\n",
    "Example: [{{\"metric_type\":\"revenue\",\"value\":2500,\"unit\":\"millions\",\"year\":2023,\"confidence\":0.9,\"explanation\":\"annual revenue\"}}]\n",
    "\n",
    "If no KPIs found, return: []\n",
    "\"\"\"\n",
    "\n",
    "# ============= Ollama Implementation =============\n",
    "class OllamaExtractor(BaseKPIExtractor):\n",
    "    \"\"\"Local Ollama-based extraction\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, temperature: float = 0.0):\n",
    "        import requests\n",
    "        self.model = model_name\n",
    "        self.temperature = temperature\n",
    "        self.base_url = \"http://localhost:11434\"\n",
    "        self.requests = requests\n",
    "        \n",
    "    def health_check(self) -> bool:\n",
    "        try:\n",
    "            resp = self.requests.get(f\"{self.base_url}/api/tags\")\n",
    "            models = [m['name'] for m in resp.json().get('models', [])]\n",
    "            if self.model not in models:\n",
    "                logger.warning(f\"Model {self.model} not found. Available: {models}\")\n",
    "                return False\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ollama not available: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def extract(self, text: str, metadata: Dict[str, Any]) -> List[Dict]:\n",
    "        prompt = self.get_prompt(text, metadata)\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"format\": \"json\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            resp = self.requests.post(\n",
    "                f\"{self.base_url}/api/generate\",\n",
    "                json=payload,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if resp.status_code == 200:\n",
    "                result = json.loads(resp.json()['response'])\n",
    "                if isinstance(result, list):\n",
    "                    # Add metadata to each KPI\n",
    "                    for kpi in result:\n",
    "                        kpi.update({\n",
    "                            'sentenceID': metadata.get('sentenceID'),\n",
    "                            'cik': metadata.get('cik'),\n",
    "                            'ticker': metadata.get('ticker')\n",
    "                        })\n",
    "                    return result\n",
    "                return []\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Extraction failed: {e}\")\n",
    "            return []\n",
    "\n",
    "# ============= Cloud API Implementation =============\n",
    "class CloudAPIExtractor(BaseKPIExtractor):\n",
    "    \"\"\"Cloud provider API extraction (Anthropic, OpenAI, etc.)\"\"\"\n",
    "    \n",
    "    def __init__(self, provider: str, api_key: str, model_name: str, temperature: float = 0.0):\n",
    "        self.provider = provider\n",
    "        self.api_key = api_key\n",
    "        self.model = model_name\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        if provider == \"anthropic\":\n",
    "            from anthropic import Anthropic\n",
    "            self.client = Anthropic(api_key=api_key)\n",
    "        elif provider == \"openai\":\n",
    "            from openai import OpenAI\n",
    "            self.client = OpenAI(api_key=api_key)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown provider: {provider}\")\n",
    "    \n",
    "    def health_check(self) -> bool:\n",
    "        # Simple check - could be enhanced\n",
    "        return self.api_key is not None and len(self.api_key) > 0\n",
    "    \n",
    "    def extract(self, text: str, metadata: Dict[str, Any]) -> List[Dict]:\n",
    "        prompt = self.get_prompt(text, metadata)\n",
    "        \n",
    "        try:\n",
    "            if self.provider == \"anthropic\":\n",
    "                response = self.client.messages.create(\n",
    "                    model=self.model,\n",
    "                    max_tokens=1000,\n",
    "                    temperature=self.temperature,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                )\n",
    "                result = json.loads(response.content[0].text)\n",
    "            \n",
    "            elif self.provider == \"openai\":\n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    temperature=self.temperature,\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                )\n",
    "                result = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            if isinstance(result, list):\n",
    "                for kpi in result:\n",
    "                    kpi.update({\n",
    "                        'sentenceID': metadata.get('sentenceID'),\n",
    "                        'cik': metadata.get('cik'),\n",
    "                        'ticker': metadata.get('ticker')\n",
    "                    })\n",
    "                return result\n",
    "            return []\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Cloud API extraction failed: {e}\")\n",
    "            return []\n",
    "\n",
    "# ============= Transformers Fallback =============\n",
    "class TransformersExtractor(BaseKPIExtractor):\n",
    "    \"\"\"Fallback to smaller transformer models\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"deepset/roberta-base-squad2\"):\n",
    "        from transformers import pipeline\n",
    "        import torch\n",
    "        \n",
    "        self.device = 0 if torch.cuda.is_available() else -1\n",
    "        self.qa_pipeline = pipeline(\n",
    "            \"question-answering\",\n",
    "            model=model_name,\n",
    "            device=self.device\n",
    "        )\n",
    "    \n",
    "    def health_check(self) -> bool:\n",
    "        try:\n",
    "            test = self.qa_pipeline(\n",
    "                question=\"What is the value?\",\n",
    "                context=\"The value is $100 million\"\n",
    "            )\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def extract(self, text: str, metadata: Dict[str, Any]) -> List[Dict]:\n",
    "        \"\"\"Simplified extraction for QA models\"\"\"\n",
    "        questions = [\n",
    "            \"What are the financial metrics and values?\",\n",
    "            \"What is the revenue or earnings?\"\n",
    "        ]\n",
    "        \n",
    "        kpis = []\n",
    "        for question in questions:\n",
    "            try:\n",
    "                answer = self.qa_pipeline(question=question, context=text)\n",
    "                if answer['score'] > 0.3:\n",
    "                    # Basic parsing - less sophisticated than LLM\n",
    "                    kpi = {\n",
    "                        'metric_type': 'financial_metric',\n",
    "                        'value': answer['answer'],\n",
    "                        'confidence': answer['score'],\n",
    "                        'sentenceID': metadata.get('sentenceID'),\n",
    "                        'cik': metadata.get('cik'),\n",
    "                        'ticker': metadata.get('ticker')\n",
    "                    }\n",
    "                    kpis.append(kpi)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return kpis\n",
    "\n",
    "# ============= Data Preparation =============\n",
    "class FinancialDataset:\n",
    "    \"\"\"Dataset preparation with proper sampling\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path: str, sample_size: Optional[int] = None, \n",
    "                 random_seed: int = 42):\n",
    "        self.data_path = data_path\n",
    "        self.sample_size = sample_size\n",
    "        self.random_seed = random_seed\n",
    "        self.df = None\n",
    "        \n",
    "    def prepare(self) -> pl.DataFrame:\n",
    "        \"\"\"Load and prepare dataset with proper sampling\"\"\"\n",
    "        logger.info(f\"Loading data from {self.data_path}\")\n",
    "        \n",
    "        # Lazy load for efficiency\n",
    "        df = pl.scan_parquet(self.data_path).collect()\n",
    "        \n",
    "        # Apply sampling if specified\n",
    "        if self.sample_size and self.sample_size < len(df):\n",
    "            logger.info(f\"Random sampling {self.sample_size} from {len(df)} rows\")\n",
    "            df = df.sample(n=self.sample_size, seed=self.random_seed)\n",
    "        \n",
    "        logger.info(f\"Dataset ready: {len(df)} sentences\")\n",
    "        \n",
    "        # Show distribution\n",
    "        section_dist = df.group_by(\"section\").count().sort(\"count\", descending=True)\n",
    "        logger.info(\"Section distribution:\")\n",
    "        for row in section_dist.head(5).iter_rows(named=True):\n",
    "            logger.info(f\"  Section {row['section']}: {row['count']}\")\n",
    "        \n",
    "        self.df = df\n",
    "        return df\n",
    "\n",
    "# ============= Main Pipeline =============\n",
    "class FinancialKPIPipeline:\n",
    "    \"\"\"Main extraction pipeline with checkpointing\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ExtractionConfig):\n",
    "        self.config = config\n",
    "        self.extractor = self._initialize_extractor()\n",
    "        self.dataset = FinancialDataset(\n",
    "            config.data_path,\n",
    "            config.sample_size,\n",
    "            config.random_seed\n",
    "        )\n",
    "        self.checkpoint_path = Path(config.output_dir) / \"checkpoint.json\"\n",
    "        \n",
    "    def _initialize_extractor(self) -> BaseKPIExtractor:\n",
    "        \"\"\"Initialize appropriate backend\"\"\"\n",
    "        if self.config.backend == \"ollama\":\n",
    "            extractor = OllamaExtractor(\n",
    "                self.config.model_name,\n",
    "                self.config.temperature\n",
    "            )\n",
    "        elif self.config.backend == \"anthropic\":\n",
    "            import os\n",
    "            extractor = CloudAPIExtractor(\n",
    "                provider=\"anthropic\",\n",
    "                api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "                model_name=self.config.model_name,\n",
    "                temperature=self.config.temperature\n",
    "            )\n",
    "        elif self.config.backend == \"transformers\":\n",
    "            extractor = TransformersExtractor(self.config.model_name)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown backend: {self.config.backend}\")\n",
    "        \n",
    "        if not extractor.health_check():\n",
    "            raise RuntimeError(f\"Backend {self.config.backend} not available\")\n",
    "        \n",
    "        logger.info(f\"Initialized {self.config.backend} backend\")\n",
    "        return extractor\n",
    "    \n",
    "    def _load_checkpoint(self) -> int:\n",
    "        \"\"\"Load checkpoint if exists\"\"\"\n",
    "        if self.checkpoint_path.exists():\n",
    "            with open(self.checkpoint_path, 'r') as f:\n",
    "                checkpoint = json.load(f)\n",
    "                logger.info(f\"Resuming from sentence {checkpoint['last_processed']}\")\n",
    "                return checkpoint['last_processed']\n",
    "        return 0\n",
    "    \n",
    "    def _save_checkpoint(self, last_idx: int, kpis: List[Dict]):\n",
    "        \"\"\"Save progress checkpoint\"\"\"\n",
    "        checkpoint = {\n",
    "            'last_processed': last_idx,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'kpis_found': len(kpis)\n",
    "        }\n",
    "        with open(self.checkpoint_path, 'w') as f:\n",
    "            json.dump(checkpoint, f)\n",
    "    \n",
    "    def run(self) -> pl.DataFrame:\n",
    "        \"\"\"Execute extraction pipeline\"\"\"\n",
    "        # Prepare data\n",
    "        df = self.dataset.prepare()\n",
    "        \n",
    "        # Check for existing checkpoint\n",
    "        start_idx = self._load_checkpoint()\n",
    "        \n",
    "        # Process sentences\n",
    "        all_kpis = []\n",
    "        \n",
    "        for idx, row in enumerate(tqdm(\n",
    "            df.iter_rows(named=True), \n",
    "            total=len(df),\n",
    "            initial=start_idx,\n",
    "            desc=\"Extracting KPIs\"\n",
    "        )):\n",
    "            if idx < start_idx:\n",
    "                continue\n",
    "            \n",
    "            metadata = {\n",
    "                'sentenceID': row['sentenceID'],\n",
    "                'cik': row['cik'],\n",
    "                'ticker': row.get('tickers', row.get('ticker')),\n",
    "                'company': row.get('name', row.get('company')),\n",
    "                'section': row['section'],\n",
    "                'reportDate': str(row.get('reportDate', ''))\n",
    "            }\n",
    "            \n",
    "            # Extract with retries\n",
    "            for attempt in range(self.config.max_retries):\n",
    "                kpis = self.extractor.extract(row['sentence'], metadata)\n",
    "                if kpis:\n",
    "                    all_kpis.extend(kpis)\n",
    "                    break\n",
    "                time.sleep(1)  # Brief pause between retries\n",
    "            \n",
    "            # Checkpoint periodically\n",
    "            if idx > 0 and idx % self.config.checkpoint_interval == 0:\n",
    "                self._save_checkpoint(idx, all_kpis)\n",
    "                logger.info(f\"Checkpoint: {idx}/{len(df)}, KPIs: {len(all_kpis)}\")\n",
    "        \n",
    "        # Create final dataframe\n",
    "        if all_kpis:\n",
    "            kpi_df = pl.DataFrame(all_kpis)\n",
    "            output_path = Path(self.config.output_dir) / f\"kpis_{datetime.now():%Y%m%d_%H%M%S}.parquet\"\n",
    "            kpi_df.write_parquet(output_path)\n",
    "            logger.info(f\"Saved {len(kpi_df)} KPIs to {output_path}\")\n",
    "            return kpi_df\n",
    "        else:\n",
    "            logger.warning(\"No KPIs extracted\")\n",
    "            return pl.DataFrame()\n",
    "\n",
    "# ============= Usage =============\n",
    "\n",
    "\n",
    "## Allows for ollama, anthropic, transformers backends.\n",
    "if __name__ == \"__main__\":\n",
    "    # Configure extraction\n",
    "    config = ExtractionConfig(\n",
    "\n",
    "        # data_path=r\"D:\\path\\to\\sec_finrag_1M_sample.parquet\",\n",
    "        data_path=r\"D:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\finrag-insights-mlops\\data\\exports\\sec_finrag_1M_sample.parquet\",\n",
    "        sample_size=100, \n",
    "        backend=\"ollama\",  # or \"anthropic\", \"transformers\"\n",
    "        model_name=\"qwen2.5:14b-instruct-q4_K_M\",\n",
    "        checkpoint_interval=100\n",
    "    )\n",
    "    \n",
    "    # Run pipeline\n",
    "    pipeline = FinancialKPIPipeline(config)\n",
    "    kpi_df = pipeline.run()\n",
    "    \n",
    "    # Display results\n",
    "    if len(kpi_df) > 0:\n",
    "        print(f\"\\nExtracted {len(kpi_df)} KPIs\")\n",
    "        print(\"\\nSample results:\")\n",
    "        print(kpi_df.select(['metric_type', 'value', 'unit', 'confidence']).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eb76e9",
   "metadata": {},
   "source": [
    "#### ----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076a7126",
   "metadata": {},
   "source": [
    "### Improvement: llama CPP server + GGUF model + HTTP calls from Jupyter notebook.\n",
    "- Pretty easy—download one EXE, a GGUF model, run a command, and call it from Jupyter notebook like any REST API. No WSL/Linux needed..\n",
    "- Download → double-click/run → call a REST endpoint. \n",
    "- On Windows + CUDA, llama.cpp server with --cont-batching gives you real, batched throughput. Swap Ollama call for the HTTP call above and you’ll see a big step up—especially with 7B (or 3B) GGUF.\n",
    "\n",
    "- PyTorch in Conda ships its own CUDA/cuDNN runtime. It’s used only by PyTorch.\n",
    "- llama.cpp (cuBLAS build) is a separate program. It uses CUDA via NVIDIA driver (and the CUDA runtime it’s linked against). It does not depend on Conda CUDA at all.\n",
    "- Because you call llama.cpp via HTTP, Python kernel/env is irrelevant to GPU acceleration—think “call a local web service.”\n",
    "\n",
    "\n",
    "```\n",
    "cd C:\\llama\n",
    ".\\llama-server.exe `\n",
    "  -m \"C:\\models\\qwen2.5-7b\\Qwen2.5-7B-Instruct-Q4_K_M.gguf\" `\n",
    "  --port 8080 `\n",
    "  --ctx-size 1024 `\n",
    "  --gpu-layers -1 `\n",
    "  --cont-batching `\n",
    "  --parallel 16 `\n",
    "  --api\n",
    "\n",
    "--gpu-layers -1 uses 3080 Ti fully.\n",
    "--cont-batching gives real server-side concurrency.\n",
    "--parallel controls how many simultaneous requests it merges.\n",
    "```\n",
    "\n",
    "- nvidia-smi = NVIDIA driver info + the maximum CUDA version the driver supports (runtime capability). CUDA 13.0 means the driver can run binaries built for up to CUDA 13 (and earlier 12.x).\n",
    "- nvcc --version = your installed CUDA Toolkit compiler version (used for building CUDA code), here 12.1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e13de62",
   "metadata": {},
   "source": [
    "### Details 1:\n",
    "- you’re just running a tiny web service on your own PC that loads a GGUF model into GPU VRAM and answers HTTP requests. “chat/completions” bit is only the API shape.\n",
    "- llama.cpp : fast C/CUDA program that runs LLMs locally.\n",
    "- llama-server.exe : precompiled Windows executable of llama.cpp with REST API support.\n",
    "- Loads a model once into VRAM and exposes a HTTP API on http://localhost:PORT.\n",
    "- GGUF model: contains the LLM weights in a quantized format optimized for llama.cpp.\n",
    "- download it once and point the server to it with -m <path.gguf>.\n",
    "- CUDA/cuBLAS DLLs: use the NVIDIA driver, not your Conda/PyTorch CUDA. Let llama.cpp run on your NVIDIA GPU.\n",
    "\n",
    "### Details 2:\n",
    "- llama-server purposely mimics the OpenAI Chat Completions API. \n",
    "- i.e. can reuse tons of existing client code/tools., JSON output controls like response_format {}, \n",
    "- convention for message formatting (system/user/assistant) and options (max_tokens, temperature, etc.), even though it’s all local.\n",
    "- Two ways to run models with llama.cpp: llama-cli or llama.exe runs a single prompt → single output in the terminal, llama-server.exe loads the model once, then you send many requests from Python. \n",
    "\n",
    "\n",
    "```\n",
    "Your Notebook  --HTTP POST-->  llama-server (on your PC)  --CUDA-->  GPU\n",
    "                                 ^  keeps model in VRAM  ^\n",
    "                                 |  merges requests      |\n",
    "                               OpenAI-style JSON        GGUF weights\n",
    "```\n",
    "\n",
    "### Details 3:\n",
    "**in the other hf_llama_debug.ipynb file**, just downloaded - ✓ downloaded: C:\\llama_server\\models\\qwen2p5_3b\\Qwen2.5-3B-Instruct-Q4_K_M.gguf. \n",
    "\n",
    "**Server life cycle**:\n",
    "1. You launch llama-server.exe -m <model.gguf> --api --cont-batching ...\n",
    "2. It loads weights into VRAM once (watch with nvidia-smi).\n",
    "3. It listens on localhost:8080.\n",
    "\n",
    "**Request life cycle**:\n",
    "1. Python builds a short prompt with your schema.\n",
    "2. POST /v1/chat/completions (JSON options like max_tokens, temperature).\n",
    "3. Server decodes on GPU (possibly batched with other requests).\n",
    "4. You receive JSON (your KPI objects), parse, validate, save.\n",
    "\n",
    "**Scaling knobs**\n",
    "1. Smaller model (3B) → faster.\n",
    "2. --parallel up to ~8–24 → more concurrent requests merged.\n",
    "3. Short prompts + max_tokens<=128 → big speed gains.\n",
    "4. Keep temperature=0 and top_p low for deterministic, compact outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b102d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63ea1ad3",
   "metadata": {},
   "source": [
    "### Trace one sentence through the pipeline:\n",
    "**Input**: \"Operating income increased 23% to $1.4 billion, driven by cloud revenue growth\"\n",
    "1, 2, 3, 4. - Now deleted. Classification - NER - Dependency Parsing - Relation Linking etc. Not needed.\n",
    "\n",
    "5. Improvement: \n",
    "- Count temporal markers (years, quarters, months), Count value entities (numbers with units), Count KPI keywords ?\n",
    "- because sentences with multiple temporal markers + multiple values.=\n",
    "- i.e. anchor points, metric clusters, binding.\n",
    "- **No** - Cut down on the 'temporal matrices of data' concept.\n",
    "- Transformers know PEs, Attn mechanisms, Context windows, Fin Pretraining.\n",
    "- Dont go for - Dependency parsing, Custom NER training, Grammar rules, Temporal matrices.\n",
    "- Go for - FinBERT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45a5490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db3a91ad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6618dec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/health                  -> 200\n",
      "http://localhost:8080/v1/models               -> 200\n",
      "http://localhost:8080/props                   -> 200\n",
      "http://localhost:8080/routes                  -> 404\n"
     ]
    }
   ],
   "source": [
    "## Testing 1: Probe eps.\n",
    "\n",
    "import subprocess, requests, time, os\n",
    "\n",
    "LLAMA_DIR = r\"C:\\llama_server\\llama_cpp_b6814\"   # adjust if different\n",
    "exe = os.path.join(LLAMA_DIR, \"llama-server.exe\")\n",
    "\n",
    "# 1️⃣  start server with --api and --props (no model, short run)\n",
    "proc = subprocess.Popen(\n",
    "    [exe, \"--api\", \"--props\", \"--port\", \"8080\"],\n",
    "    stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True\n",
    ")\n",
    "time.sleep(5)  # give it a few seconds to boot\n",
    "\n",
    "# 2️⃣  probe endpoints\n",
    "for url in [\n",
    "    \"http://localhost:8080/health\",\n",
    "    \"http://localhost:8080/v1/models\",\n",
    "    \"http://localhost:8080/props\",\n",
    "    \"http://localhost:8080/routes\",\n",
    "]:\n",
    "    try:\n",
    "        r = requests.get(url, timeout=1)\n",
    "        print(f\"{url:<45} -> {r.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{url:<45} -> FAIL ({e})\")\n",
    "\n",
    "# 3️⃣  clean up\n",
    "proc.terminate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad09c4",
   "metadata": {},
   "source": [
    "### Llamma server cpp fails massively, even at the setup stage. Issues, hard to track argument conflicts, server dying out for no reason, not starting or loading.\n",
    "\n",
    "### Choosing llama cpp python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa2c0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 38 key-value pairs and 339 tensors from C:\\llama_server\\models\\qwen2p5_7b\\Qwen2.5-7B-Instruct-Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Qwen2.5 7B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Qwen2.5\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 7B\n",
      "llama_model_loader: - kv   6:                            general.license str              = apache-2.0\n",
      "llama_model_loader: - kv   7:                       general.license.link str              = https://huggingface.co/Qwen/Qwen2.5-7...\n",
      "llama_model_loader: - kv   8:                   general.base_model.count u32              = 1\n",
      "llama_model_loader: - kv   9:                  general.base_model.0.name str              = Qwen2.5 7B\n",
      "llama_model_loader: - kv  10:          general.base_model.0.organization str              = Qwen\n",
      "llama_model_loader: - kv  11:              general.base_model.0.repo_url str              = https://huggingface.co/Qwen/Qwen2.5-7B\n",
      "llama_model_loader: - kv  12:                               general.tags arr[str,2]       = [\"chat\", \"text-generation\"]\n",
      "llama_model_loader: - kv  13:                          general.languages arr[str,1]       = [\"en\"]\n",
      "llama_model_loader: - kv  14:                          qwen2.block_count u32              = 28\n",
      "llama_model_loader: - kv  15:                       qwen2.context_length u32              = 32768\n",
      "llama_model_loader: - kv  16:                     qwen2.embedding_length u32              = 3584\n",
      "llama_model_loader: - kv  17:                  qwen2.feed_forward_length u32              = 18944\n",
      "llama_model_loader: - kv  18:                 qwen2.attention.head_count u32              = 28\n",
      "llama_model_loader: - kv  19:              qwen2.attention.head_count_kv u32              = 4\n",
      "llama_model_loader: - kv  20:                       qwen2.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  21:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  22:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  23:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  24:                         tokenizer.ggml.pre str              = qwen2\n",
      "llama_model_loader: - kv  25:                      tokenizer.ggml.tokens arr[str,152064]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  26:                  tokenizer.ggml.token_type arr[i32,152064]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  27:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 151645\n",
      "llama_model_loader: - kv  29:            tokenizer.ggml.padding_token_id u32              = 151643\n",
      "llama_model_loader: - kv  30:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  31:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  32:                    tokenizer.chat_template str              = {%- if tools %}\\n    {{- '<|im_start|>...\n",
      "llama_model_loader: - kv  33:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  34:                      quantize.imatrix.file str              = /models_out/Qwen2.5-7B-Instruct-GGUF/...\n",
      "llama_model_loader: - kv  35:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  36:             quantize.imatrix.entries_count i32              = 196\n",
      "llama_model_loader: - kv  37:              quantize.imatrix.chunks_count i32              = 128\n",
      "llama_model_loader: - type  f32:  141 tensors\n",
      "llama_model_loader: - type q5_K:  169 tensors\n",
      "llama_model_loader: - type q6_K:   29 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q5_K - Medium\n",
      "print_info: file size   = 5.07 GiB (5.71 BPW) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 151661 '<|fim_suffix|>' is not marked as EOG\n",
      "load: control token: 151649 '<|box_end|>' is not marked as EOG\n",
      "load: control token: 151647 '<|object_ref_end|>' is not marked as EOG\n",
      "load: control token: 151654 '<|vision_pad|>' is not marked as EOG\n",
      "load: control token: 151659 '<|fim_prefix|>' is not marked as EOG\n",
      "load: control token: 151648 '<|box_start|>' is not marked as EOG\n",
      "load: control token: 151644 '<|im_start|>' is not marked as EOG\n",
      "load: control token: 151646 '<|object_ref_start|>' is not marked as EOG\n",
      "load: control token: 151650 '<|quad_start|>' is not marked as EOG\n",
      "load: control token: 151651 '<|quad_end|>' is not marked as EOG\n",
      "load: control token: 151652 '<|vision_start|>' is not marked as EOG\n",
      "load: control token: 151653 '<|vision_end|>' is not marked as EOG\n",
      "load: control token: 151655 '<|image_pad|>' is not marked as EOG\n",
      "load: control token: 151656 '<|video_pad|>' is not marked as EOG\n",
      "load: control token: 151660 '<|fim_middle|>' is not marked as EOG\n",
      "load: printing all EOG tokens:\n",
      "load:   - 151643 ('<|endoftext|>')\n",
      "load:   - 151645 ('<|im_end|>')\n",
      "load:   - 151662 ('<|fim_pad|>')\n",
      "load:   - 151663 ('<|repo_name|>')\n",
      "load:   - 151664 ('<|file_sep|>')\n",
      "load: special tokens cache size = 22\n",
      "load: token to piece cache size = 0.9310 MB\n",
      "print_info: arch             = qwen2\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 3584\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 28\n",
      "print_info: n_head_kv        = 4\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 7\n",
      "print_info: n_embd_k_gqa     = 512\n",
      "print_info: n_embd_v_gqa     = 512\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-06\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 18944\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = -1\n",
      "print_info: rope type        = 2\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.62 B\n",
      "print_info: general.name     = Qwen2.5 7B Instruct\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 152064\n",
      "print_info: n_merges         = 151387\n",
      "print_info: BOS token        = 151643 '<|endoftext|>'\n",
      "print_info: EOS token        = 151645 '<|im_end|>'\n",
      "print_info: EOT token        = 151645 '<|im_end|>'\n",
      "print_info: PAD token        = 151643 '<|endoftext|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: FIM PRE token    = 151659 '<|fim_prefix|>'\n",
      "print_info: FIM SUF token    = 151661 '<|fim_suffix|>'\n",
      "print_info: FIM MID token    = 151660 '<|fim_middle|>'\n",
      "print_info: FIM PAD token    = 151662 '<|fim_pad|>'\n",
      "print_info: FIM REP token    = 151663 '<|repo_name|>'\n",
      "print_info: FIM SEP token    = 151664 '<|file_sep|>'\n",
      "print_info: EOG token        = 151643 '<|endoftext|>'\n",
      "print_info: EOG token        = 151645 '<|im_end|>'\n",
      "print_info: EOG token        = 151662 '<|fim_pad|>'\n",
      "print_info: EOG token        = 151663 '<|repo_name|>'\n",
      "print_info: EOG token        = 151664 '<|file_sep|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q5_K) (and 338 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =  5186.92 MiB\n",
      ".......................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 4096\n",
      "llama_context: n_ctx_per_seq = 4096\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 1000000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.58 MiB\n",
      "create_memory: n_ctx = 4096 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   224.00 MiB\n",
      "llama_kv_cache_unified: size =  224.00 MiB (  4096 cells,  28 layers,  1/1 seqs), K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 2712\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   304.00 MiB\n",
      "llama_context: graph nodes  = 1070\n",
      "llama_context: graph splits = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded in 1.0s\n",
      "✓ CUDA available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
      "Model metadata: {'general.name': 'Qwen2.5 7B Instruct', 'general.architecture': 'qwen2', 'general.type': 'model', 'general.basename': 'Qwen2.5', 'general.finetune': 'Instruct', 'general.size_label': '7B', 'general.license': 'apache-2.0', 'qwen2.attention.head_count_kv': '4', 'general.license.link': 'https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/blob/main/LICENSE', 'general.base_model.count': '1', 'general.base_model.0.name': 'Qwen2.5 7B', 'general.base_model.0.organization': 'Qwen', 'general.base_model.0.repo_url': 'https://huggingface.co/Qwen/Qwen2.5-7B', 'qwen2.block_count': '28', 'qwen2.context_length': '32768', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'qwen2.embedding_length': '3584', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '151643', 'qwen2.feed_forward_length': '18944', 'qwen2.attention.head_count': '28', 'tokenizer.ggml.padding_token_id': '151643', 'qwen2.rope.freq_base': '1000000.000000', 'qwen2.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.eos_token_id': '151645', 'general.file_type': '17', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'qwen2', 'tokenizer.ggml.add_bos_token': 'false', 'tokenizer.chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n', 'quantize.imatrix.chunks_count': '128', 'quantize.imatrix.file': '/models_out/Qwen2.5-7B-Instruct-GGUF/Qwen2.5-7B-Instruct.imatrix', 'quantize.imatrix.entries_count': '196'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "import time\n",
    "\n",
    "MODEL_PATH = r\"C:\\llama_server\\models\\qwen2p5_7b\\Qwen2.5-7B-Instruct-Q5_K_M.gguf\"\n",
    "\n",
    "print(\"Loading model...\")\n",
    "start = time.time()\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=MODEL_PATH,\n",
    "    n_gpu_layers=35,  # Use GPU\n",
    "    n_ctx=4096,\n",
    "    verbose=True  # See if CUDA is being used\n",
    ")\n",
    "\n",
    "print(f\"✓ Loaded in {time.time()-start:.1f}s\")\n",
    "print(f\"✓ CUDA available: {llm.model_params.n_gpu_layers > 0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc6d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Local LLM KPI extractor (llama.cpp server, Windows, CUDA) ===\n",
    "# lean version: download GGUF (if missing) -> start server -> run 7-sentence test.\n",
    "\n",
    "# native caused TONS of errors. server build that supports the OpenAI-style /v1/* API (and --props).\n",
    "# \n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# test_sentences = [\n",
    "#     \"For 2018, we estimate that mobile advertising revenue represented approximately 92% of total advertising revenue, as compared with approximately 88% in 2017.\",\n",
    "#     \"Realization of deferred tax assets associated with net operating loss and credit carryforwards is dependent upon generating sufficient taxable income prior to their expiration in the appropriate tax jurisdiction.\",\n",
    "#     \"A reduction of 85 million BOE was recorded in Canada, primarily from commodity price effects at Kaybob Duvernay.\",\n",
    "#     \"2018 compared to 2017 The Other segment reported net income of $14 million for the year ended December 31, 2018, compared to net loss of $71 million for the year ended December 31, 2017.\",\n",
    "#     \"Future policy benefits for individual life insurance and annuity policies consider crediting rates ranging from 2 1/2% to 6% for life insurance and 2% to 9 1/2% for annuities.\",\n",
    "#     \"The following table presents restructuring activity for the years ended June 30, 2019 and 2018: Separation Costs Employee separation charges for the years ended June 30, 2019 and 2018 relate to severance packages for approximately 1,810 and 2,720 employees, respectively.\",\n",
    "#     \"In May 2017, we issued $750.0 million of 2.35 percent fixed-rate notes due in May 2022, $750.0 million of 3.10 percent fixed-rate notes due in May 2027, and $750.0 million of 3.95 percent fixed-rate notes due in May 2047, with interest to be paid semi-annually.\"\n",
    "#     ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd8a4c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model... (this takes 10-20 seconds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded in 0.9 seconds\n",
      "\n",
      "======================================================================\n",
      "Testing KPI Extraction - Simple & Direct\n",
      "======================================================================\n",
      "\n",
      "[1/7] Processing...\n",
      "Text: For 2018, we estimate that mobile advertising revenue represented approximately ...\n",
      "✓ Found 1 KPIs in 11.9s:\n",
      "  • revenue: 92 percent (2018)\n",
      "\n",
      "[2/7] Processing...\n",
      "Text: Realization of deferred tax assets associated with net operating loss and credit...\n",
      "✗ No KPIs found (4.5s)\n",
      "\n",
      "[3/7] Processing...\n",
      "Text: A reduction of 85 million BOE was recorded in Canada, primarily from commodity p...\n",
      "✗ No KPIs found (4.2s)\n",
      "\n",
      "[4/7] Processing...\n",
      "Text: 2018 compared to 2017 The Other segment reported net income of $14 million for t...\n",
      "✓ Found 2 KPIs in 20.4s:\n",
      "  • earnings: 14 USD_millions (2018)\n",
      "  • earnings: -71 USD_millions (2017)\n",
      "\n",
      "[5/7] Processing...\n",
      "Text: Future policy benefits for individual life insurance and annuity policies consid...\n",
      "✓ Found 4 KPIs in 25.3s:\n",
      "  • revenue: 2.5 percent\n",
      "  • revenue: 6 percent\n",
      "  • revenue: 2 percent\n",
      "  • revenue: 9.5 percent\n",
      "\n",
      "[6/7] Processing...\n",
      "Text: The following table presents restructuring activity for the years ended June 30,...\n",
      "✓ Found 2 KPIs in 15.4s:\n",
      "  • expenses: 1810 count (2019)\n",
      "  • expenses: 2720 count (2018)\n",
      "\n",
      "[7/7] Processing...\n",
      "Text: In May 2017, we issued $750.0 million of 2.35 percent fixed-rate notes due in Ma...\n",
      "✓ Found 5 KPIs in 28.3s:\n",
      "  • debt: 750 USD_millions (2017)\n",
      "  • debt: 2.35 percent (2017)\n",
      "  • debt: 3.1 percent (2017)\n",
      "  • debt: 3.95 percent (2017)\n",
      "  • debt: 0.5 percent (2017)\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Sentences processed: 7\n",
      "Successful extractions: 5/7\n",
      "Total KPIs found: 14\n",
      "Average time per sentence: 15.7s\n",
      "Total processing time: 110.1s\n",
      "\n",
      "Extrapolated for 1M sentences:\n",
      "  Time: 4367.7 hours\n",
      "  With 10 parallel processes: 436.8 hours\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SIMPLE KPI Extractor using llama-cpp-python directly\n",
    "No server, no async, no complexity - just works!\n",
    "\"\"\"\n",
    "\n",
    "from llama_cpp import Llama\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import time\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: Install llama-cpp-python with CUDA support\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Run this in your terminal ONCE:\n",
    "\n",
    "pip uninstall llama-cpp-python -y\n",
    "set CMAKE_ARGS=-DGGML_CUDA=on\n",
    "pip install llama-cpp-python --no-cache-dir\n",
    "\n",
    "That's it for setup!\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "MODEL_PATH = r\"C:\\llama_server\\models\\qwen2p5_7b\\Qwen2.5-7B-Instruct-Q5_K_M.gguf\"\n",
    "\n",
    "# Model parameters\n",
    "N_GPU_LAYERS = 35  # Adjust based on your VRAM (35 should work for 7B model)\n",
    "N_CTX = 4096       # Context window\n",
    "N_BATCH = 512      # Batch size for prompt processing\n",
    "TEMPERATURE = 0.1   # Low for consistent output\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD MODEL ONCE\n",
    "# =============================================================================\n",
    "print(\"Loading model... (this takes 10-20 seconds)\")\n",
    "start_time = time.time()\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=MODEL_PATH,\n",
    "    n_gpu_layers=N_GPU_LAYERS,  # GPU acceleration\n",
    "    n_ctx=N_CTX,                 # Context window  \n",
    "    n_batch=N_BATCH,             # Batch size\n",
    "    verbose=False,               # Set to True if you want to see what's happening\n",
    ")\n",
    "\n",
    "print(f\"✓ Model loaded in {time.time() - start_time:.1f} seconds\")\n",
    "\n",
    "# =============================================================================\n",
    "# SIMPLE KPI EXTRACTION\n",
    "# =============================================================================\n",
    "\n",
    "def extract_kpis(text: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Extract KPIs from a single sentence\n",
    "    Simple, no async, no complexity\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simple, direct prompt\n",
    "    prompt = f\"\"\"Extract financial numbers from this sentence and output JSON array.\n",
    "\n",
    "Sentence: {text}\n",
    "\n",
    "Output format:\n",
    "[{{\"category\": \"revenue\", \"value\": 92, \"unit\": \"percent\", \"year\": 2018}}]\n",
    "\n",
    "Categories: revenue, earnings, debt, expenses, employees, assets, ratios\n",
    "Units: percent, USD_millions, USD_billions, count, BOE, ratio\n",
    "\n",
    "Output JSON array only:\"\"\"\n",
    "    \n",
    "    # Generate response\n",
    "    try:\n",
    "        response = llm(\n",
    "            prompt,\n",
    "            max_tokens=256,\n",
    "            temperature=TEMPERATURE,\n",
    "            stop=[\"```\", \"\\n\\n\"],  # Stop at code blocks or double newline\n",
    "            echo=False,  # Don't echo the prompt\n",
    "        )\n",
    "        \n",
    "        # Extract text from response\n",
    "        output = response['choices'][0]['text'].strip()\n",
    "        \n",
    "        # Clean up JSON\n",
    "        # Try to find JSON array\n",
    "        json_match = re.search(r'\\[.*?\\]', output, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_str = json_match.group(0)\n",
    "            # Basic cleanup\n",
    "            json_str = json_str.replace(\"'\", '\"')\n",
    "            json_str = re.sub(r',\\s*}', '}', json_str)\n",
    "            json_str = re.sub(r',\\s*]', ']', json_str)\n",
    "            \n",
    "            try:\n",
    "                data = json.loads(json_str)\n",
    "                return data if isinstance(data, list) else [data]\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {str(e)[:100]}\")\n",
    "    \n",
    "    return []\n",
    "\n",
    "# =============================================================================\n",
    "# TEST ON YOUR SENTENCES\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Test extraction on your 7 sentences\"\"\"\n",
    "    \n",
    "    test_sentences = [\n",
    "        \"For 2018, we estimate that mobile advertising revenue represented approximately 92% of total advertising revenue, as compared with approximately 88% in 2017.\",\n",
    "        \"Realization of deferred tax assets associated with net operating loss and credit carryforwards is dependent upon generating sufficient taxable income prior to their expiration in the appropriate tax jurisdiction.\",\n",
    "        \"A reduction of 85 million BOE was recorded in Canada, primarily from commodity price effects at Kaybob Duvernay.\",\n",
    "        \"2018 compared to 2017 The Other segment reported net income of $14 million for the year ended December 31, 2018, compared to net loss of $71 million for the year ended December 31, 2017.\",\n",
    "        \"Future policy benefits for individual life insurance and annuity policies consider crediting rates ranging from 2 1/2% to 6% for life insurance and 2% to 9 1/2% for annuities.\",\n",
    "        \"The following table presents restructuring activity for the years ended June 30, 2019 and 2018: Separation Costs Employee separation charges for the years ended June 30, 2019 and 2018 relate to severance packages for approximately 1,810 and 2,720 employees, respectively.\",\n",
    "        \"In May 2017, we issued $750.0 million of 2.35 percent fixed-rate notes due in May 2022, $750.0 million of 3.10 percent fixed-rate notes due in May 2027, and $750.0 million of 3.95 percent fixed-rate notes due in May 2047, with interest to be paid semi-annually.\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Testing KPI Extraction - Simple & Direct\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    results = []\n",
    "    total_time = 0\n",
    "    \n",
    "    for i, sentence in enumerate(test_sentences, 1):\n",
    "        print(f\"\\n[{i}/7] Processing...\")\n",
    "        print(f\"Text: {sentence[:80]}...\")\n",
    "        \n",
    "        start = time.time()\n",
    "        kpis = extract_kpis(sentence)\n",
    "        elapsed = time.time() - start\n",
    "        total_time += elapsed\n",
    "        \n",
    "        results.append(kpis)\n",
    "        \n",
    "        if kpis:\n",
    "            print(f\"✓ Found {len(kpis)} KPIs in {elapsed:.1f}s:\")\n",
    "            for kpi in kpis:\n",
    "                cat = kpi.get('category', '?')\n",
    "                val = kpi.get('value', '?')\n",
    "                unit = kpi.get('unit', '?')\n",
    "                year = kpi.get('year', '')\n",
    "                year_str = f\" ({year})\" if year else \"\"\n",
    "                print(f\"  • {cat}: {val} {unit}{year_str}\")\n",
    "        else:\n",
    "            print(f\"✗ No KPIs found ({elapsed:.1f}s)\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    total_kpis = sum(len(r) for r in results)\n",
    "    successful = sum(1 for r in results if r)\n",
    "    \n",
    "    print(f\"Sentences processed: {len(test_sentences)}\")\n",
    "    print(f\"Successful extractions: {successful}/{len(test_sentences)}\")\n",
    "    print(f\"Total KPIs found: {total_kpis}\")\n",
    "    print(f\"Average time per sentence: {total_time/len(test_sentences):.1f}s\")\n",
    "    print(f\"Total processing time: {total_time:.1f}s\")\n",
    "    \n",
    "    # Extrapolation\n",
    "    print(f\"\\nExtrapolated for 1M sentences:\")\n",
    "    print(f\"  Time: {(1_000_000 * total_time / len(test_sentences)) / 3600:.1f} hours\")\n",
    "    print(f\"  With 10 parallel processes: {(1_000_000 * total_time / len(test_sentences)) / 3600 / 10:.1f} hours\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# =============================================================================\n",
    "# BONUS: Batch Processing Function for Production\n",
    "# =============================================================================\n",
    "\n",
    "def process_batch(sentences: List[str], batch_size: int = 10) -> List[List[Dict]]:\n",
    "    \"\"\"\n",
    "    Process multiple sentences in batches\n",
    "    Simple sequential processing - no async needed!\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        print(f\"Processing batch {i//batch_size + 1}...\")\n",
    "        \n",
    "        for sent in batch:\n",
    "            kpis = extract_kpis(sent)\n",
    "            results.append(kpis)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# =============================================================================\n",
    "# ALTERNATIVE: Using Grammar for Guaranteed JSON\n",
    "# =============================================================================\n",
    "\n",
    "def extract_with_grammar(text: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Use grammar to force valid JSON output\n",
    "    This guarantees parseable JSON but may be more restrictive\n",
    "    \"\"\"\n",
    "    \n",
    "    # JSON grammar (simplified)\n",
    "    json_grammar = r\"\"\"\n",
    "    root   ::= array\n",
    "    array  ::= \"[\" ws (object (\",\" ws object)*)? ws \"]\"\n",
    "    object ::= \"{\" ws string \":\" ws value (\",\" ws string \":\" ws value)* ws \"}\"\n",
    "    string ::= \"\\\"\" ([^\"\\\\] | \"\\\\\" .)* \"\\\"\"\n",
    "    value  ::= string | number\n",
    "    number ::= \"-\"? [0-9]+ (\".\" [0-9]+)?\n",
    "    ws     ::= [ \\t\\n]*\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"Extract KPIs from: {text}\\nOutput JSON array:\"\n",
    "    \n",
    "    response = llm(\n",
    "        prompt,\n",
    "        max_tokens=256,\n",
    "        temperature=0.1,\n",
    "        grammar=json_grammar,  # Force JSON structure\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        return json.loads(response['choices'][0]['text'])\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d784b",
   "metadata": {},
   "source": [
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54431af0",
   "metadata": {},
   "source": [
    "- 564,551 sentences at 5 seconds each = 783 hours (still too long!)\n",
    "- 564,551 sentences at 3 seconds each = 470 hours (still impractical)\n",
    "\n",
    "- The core problem: 564k sentences is still way too many for sequential LLM processing.\n",
    "- ROBERTA will miss many non-standard KPIs (reserves, coupons, headcount, policy rates, BOE, regulatory capital)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e767164b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4321c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5def2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb32e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Financial KPI Extractor - \n",
    "# Fixes context size, asyncio issues, and server arguments for Windows llama.cpp\n",
    "# \"\"\"\n",
    "\n",
    "# import os, time, json, subprocess, requests, re, asyncio, aiohttp\n",
    "# from typing import List, Dict, Optional, Tuple\n",
    "# from pathlib import Path\n",
    "# import sys\n",
    "# import nest_asyncio  # Add this to requirements\n",
    "\n",
    "# # Fix for Jupyter/IPython environments\n",
    "# try:\n",
    "#     import nest_asyncio\n",
    "#     nest_asyncio.apply()\n",
    "# except ImportError:\n",
    "#     print(\"Warning: nest_asyncio not found. Install with: pip install nest-asyncio\")\n",
    "\n",
    "# # =============================================================================\n",
    "# # CONFIGURATION - Q5_K_M Model\n",
    "# # =============================================================================\n",
    "# LLAMA_DIR = r\"C:\\llama_server\\llama_cpp_b6814\"\n",
    "# MODEL_PATH = r\"C:\\llama_server\\models\\qwen2p5_7b\\Qwen2.5-7B-Instruct-Q5_K_M.gguf\"\n",
    "\n",
    "# HOST = \"localhost\"\n",
    "# PORT = 8080\n",
    "# BASE_URL = f\"http://{HOST}:{PORT}\"\n",
    "# V1_URL = f\"{BASE_URL}/v1\"\n",
    "\n",
    "# # Server parameters - Fixed for your build\n",
    "# CTX_SIZE = 4096           \n",
    "# N_BATCH = 512            \n",
    "# PARALLEL = 8              # Reduced for stability\n",
    "# GPU_LAYERS = 35           # Specific number instead of 999\n",
    "# N_PREDICT = 256          \n",
    "# TEMPERATURE = 0.1        \n",
    "\n",
    "# # Async batching parameters\n",
    "# MAX_CONCURRENT = 4        # Start conservative\n",
    "# REQUEST_TIMEOUT = 30      \n",
    "\n",
    "# # =============================================================================\n",
    "# # SERVER MANAGEMENT - FIXED VERSION\n",
    "# # =============================================================================\n",
    "\n",
    "# def wait_for_server(base_url: str, timeout: int = 90) -> bool:\n",
    "#     \"\"\"Wait for server with proper checks\"\"\"\n",
    "#     print(f\"Waiting for server at {base_url}...\")\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     while time.time() - start_time < timeout:\n",
    "#         try:\n",
    "#             # Check health\n",
    "#             response = requests.get(f\"{base_url}/health\", timeout=2)\n",
    "#             if response.status_code == 200:\n",
    "#                 print(\"✓ Server is healthy\")\n",
    "                \n",
    "#                 # Try to get actual server info via completion endpoint\n",
    "#                 try:\n",
    "#                     # Send a test completion to verify context\n",
    "#                     test_payload = {\n",
    "#                         \"prompt\": \"test\",\n",
    "#                         \"max_tokens\": 1,\n",
    "#                         \"temperature\": 0\n",
    "#                     }\n",
    "#                     test_resp = requests.post(f\"{base_url}/completion\", json=test_payload, timeout=5)\n",
    "#                     if test_resp.status_code == 200:\n",
    "#                         print(\"✓ Completion endpoint working\")\n",
    "#                 except:\n",
    "#                     pass\n",
    "                \n",
    "#                 # Check v1 endpoints\n",
    "#                 try:\n",
    "#                     models_resp = requests.get(f\"{base_url}/v1/models\", timeout=2)\n",
    "#                     if models_resp.status_code == 200:\n",
    "#                         print(\"✓ OpenAI v1 endpoints ready\")\n",
    "#                         return True\n",
    "#                 except:\n",
    "#                     pass\n",
    "                    \n",
    "#                 return True  # Health check passed, that's enough\n",
    "#         except requests.exceptions.RequestException:\n",
    "#             pass\n",
    "#         time.sleep(1)\n",
    "    \n",
    "#     return False\n",
    "\n",
    "# def start_llama_server(\n",
    "#     model_path: str,\n",
    "#     llama_dir: str = LLAMA_DIR,\n",
    "#     port: int = PORT,\n",
    "#     ctx_size: int = CTX_SIZE,\n",
    "#     n_batch: int = N_BATCH,\n",
    "#     parallel: int = PARALLEL,\n",
    "#     gpu_layers: int = GPU_LAYERS\n",
    "# ) -> subprocess.Popen:\n",
    "#     \"\"\"Start llama-server with CORRECT arguments for Windows build b6814\"\"\"\n",
    "    \n",
    "#     exe_path = Path(llama_dir) / \"llama-server.exe\"\n",
    "#     if not exe_path.exists():\n",
    "#         raise FileNotFoundError(f\"llama-server.exe not found at {exe_path}\")\n",
    "    \n",
    "#     model_path = Path(model_path)\n",
    "#     if not model_path.exists():\n",
    "#         raise FileNotFoundError(f\"Model not found at {model_path}\")\n",
    "    \n",
    "#     # FIXED: Use the CORRECT argument format for your build\n",
    "#     # Your build uses different flags than documented\n",
    "#     cmd = [\n",
    "#         str(exe_path),\n",
    "#         \"-m\", str(model_path),\n",
    "#         \"--host\", \"0.0.0.0\",\n",
    "#         \"--port\", str(port),\n",
    "#         \"--ctx-size\", str(ctx_size),     # Try --ctx-size\n",
    "#         \"--batch-size\", str(n_batch),    # Try --batch-size\n",
    "#         \"--n-parallel\", str(parallel),   # Try --n-parallel\n",
    "#         \"--n-gpu-layers\", str(gpu_layers),  # Full form\n",
    "#         \"--cont-batching\",\n",
    "#     ]\n",
    "    \n",
    "#     print(\"=\"*70)\n",
    "#     print(\"Starting llama.cpp server with Qwen2.5-7B-Instruct Q5_K_M\")\n",
    "#     print(\"=\"*70)\n",
    "#     print(f\"\\nModel: {model_path.name}\")\n",
    "#     print(f\"Size: {model_path.stat().st_size/1e9:.2f} GB\")\n",
    "#     print(f\"Target Context: {ctx_size} tokens\")\n",
    "#     print(f\"Parallel slots: {parallel}\")\n",
    "#     print(f\"\\nCommand:\")\n",
    "#     print(\" \".join(cmd))\n",
    "#     print()\n",
    "    \n",
    "#     # Start process with proper error handling\n",
    "#     try:\n",
    "#         process = subprocess.Popen(\n",
    "#             cmd,\n",
    "#             stdout=subprocess.PIPE,\n",
    "#             stderr=subprocess.PIPE,  # Capture stderr separately\n",
    "#             text=True,\n",
    "#             bufsize=1,\n",
    "#             creationflags=subprocess.CREATE_NEW_PROCESS_GROUP if sys.platform == \"win32\" else 0\n",
    "#         )\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to start server: {e}\")\n",
    "#         raise\n",
    "    \n",
    "#     # Monitor startup\n",
    "#     print(\"Server startup output:\")\n",
    "#     for _ in range(30):\n",
    "#         line = process.stdout.readline()\n",
    "#         if line:\n",
    "#             print(f\"  {line.rstrip()}\")\n",
    "#             # Check for error indicators\n",
    "#             if \"error:\" in line.lower() or \"invalid\" in line.lower():\n",
    "#                 print(f\"\\n⚠ Detected error in output: {line}\")\n",
    "    \n",
    "#     # Check if process is still running\n",
    "#     if process.poll() is not None:\n",
    "#         print(\"\\n❌ Server exited during startup\")\n",
    "#         stderr = process.stderr.read()\n",
    "#         if stderr:\n",
    "#             print(f\"Error output: {stderr}\")\n",
    "#         raise RuntimeError(\"Server failed to start\")\n",
    "    \n",
    "#     # Wait for ready\n",
    "#     if not wait_for_server(BASE_URL, timeout=90):\n",
    "#         print(\"\\nServer not responding properly\")\n",
    "#         process.terminate()\n",
    "#         raise RuntimeError(\"Server failed to become ready\")\n",
    "    \n",
    "#     print(\"\\n✓ Server started successfully\")\n",
    "#     return process\n",
    "\n",
    "# def stop_server(process: Optional[subprocess.Popen]):\n",
    "#     \"\"\"Gracefully stop the server\"\"\"\n",
    "#     if process and process.poll() is None:\n",
    "#         print(\"\\nStopping server...\")\n",
    "#         if sys.platform == \"win32\":\n",
    "#             process.terminate()\n",
    "#         else:\n",
    "#             process.terminate()\n",
    "#         try:\n",
    "#             process.wait(timeout=10)\n",
    "#             print(\"✓ Server stopped\")\n",
    "#         except subprocess.TimeoutExpired:\n",
    "#             print(\"⚠ Force killing server...\")\n",
    "#             process.kill()\n",
    "\n",
    "# # =============================================================================\n",
    "# # KPI EXTRACTION - Simplified and Robust\n",
    "# # =============================================================================\n",
    "\n",
    "# def clean_json_response(text: str) -> str:\n",
    "#     \"\"\"Extract and clean JSON from LLM response\"\"\"\n",
    "#     # Remove markdown\n",
    "#     text = re.sub(r'```(?:json)?\\s*|\\s*```', '', text)\n",
    "    \n",
    "#     # Find JSON array\n",
    "#     array_match = re.search(r'\\[.*?\\]', text, re.DOTALL)\n",
    "#     if array_match:\n",
    "#         json_str = array_match.group(0)\n",
    "#         # Fix common issues\n",
    "#         json_str = json_str.replace(\"'\", '\"')  # Single to double quotes\n",
    "#         json_str = re.sub(r',\\s*]', ']', json_str)  # Trailing commas\n",
    "#         json_str = re.sub(r',\\s*}', '}', json_str)\n",
    "#         return json_str\n",
    "    \n",
    "#     # Find JSON object\n",
    "#     obj_match = re.search(r'\\{.*?\\}', text, re.DOTALL)\n",
    "#     if obj_match:\n",
    "#         return f\"[{obj_match.group(0)}]\"\n",
    "    \n",
    "#     return \"[]\"\n",
    "\n",
    "# async def extract_kpis_async(\n",
    "#     session: aiohttp.ClientSession,\n",
    "#     text: str,\n",
    "#     sentence_id: str,\n",
    "#     semaphore: asyncio.Semaphore\n",
    "# ) -> Tuple[str, List[Dict]]:\n",
    "#     \"\"\"Async KPI extraction with robust error handling\"\"\"\n",
    "    \n",
    "#     # Simplified prompt for better results\n",
    "#     prompt = f\"\"\"Extract numbers from: \"{text}\"\n",
    "\n",
    "# Output JSON array with: category, value, unit, year (if mentioned)\n",
    "# Categories: revenue, earnings, debt, expenses, employees, ratios\n",
    "# Units: percent, USD_millions, count, BOE\n",
    "\n",
    "# Example: [{{\"category\":\"revenue\",\"value\":92,\"unit\":\"percent\",\"year\":2018}}]\n",
    "\n",
    "# JSON only:\"\"\"\n",
    "    \n",
    "#     payload = {\n",
    "#         \"messages\": [\n",
    "#             {\"role\": \"user\", \"content\": prompt}\n",
    "#         ],\n",
    "#         \"temperature\": TEMPERATURE,\n",
    "#         \"max_tokens\": N_PREDICT,\n",
    "#         \"stream\": False,\n",
    "#     }\n",
    "    \n",
    "#     async with semaphore:\n",
    "#         try:\n",
    "#             async with session.post(\n",
    "#                 f\"{V1_URL}/chat/completions\",\n",
    "#                 json=payload,\n",
    "#                 timeout=aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)\n",
    "#             ) as response:\n",
    "#                 if response.status == 200:\n",
    "#                     result = await response.json()\n",
    "#                     content = result.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "#                     cleaned = clean_json_response(content)\n",
    "                    \n",
    "#                     try:\n",
    "#                         data = json.loads(cleaned) if cleaned else []\n",
    "#                         if isinstance(data, dict):\n",
    "#                             data = [data]\n",
    "#                         return sentence_id, data if isinstance(data, list) else []\n",
    "#                     except json.JSONDecodeError:\n",
    "#                         return sentence_id, []\n",
    "#                 else:\n",
    "#                     error_text = await response.text()\n",
    "#                     print(f\"API error {response.status} for {sentence_id}: {error_text[:100]}\")\n",
    "#                     return sentence_id, []\n",
    "                    \n",
    "#         except asyncio.TimeoutError:\n",
    "#             print(f\"Timeout for {sentence_id}\")\n",
    "#             return sentence_id, []\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error for {sentence_id}: {str(e)[:100]}\")\n",
    "#             return sentence_id, []\n",
    "\n",
    "# async def batch_extract_kpis(\n",
    "#     sentences: List[Tuple[str, str]],\n",
    "#     max_concurrent: int = MAX_CONCURRENT\n",
    "# ) -> Dict[str, List[Dict]]:\n",
    "#     \"\"\"Process sentences in parallel with progress tracking\"\"\"\n",
    "    \n",
    "#     semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    \n",
    "#     # Configure connection pool\n",
    "#     connector = aiohttp.TCPConnector(limit=max_concurrent, force_close=True)\n",
    "#     timeout = aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)\n",
    "    \n",
    "#     async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:\n",
    "#         tasks = [\n",
    "#             extract_kpis_async(session, text, sid, semaphore)\n",
    "#             for sid, text in sentences\n",
    "#         ]\n",
    "        \n",
    "#         results = {}\n",
    "#         completed = 0\n",
    "#         total = len(tasks)\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         print(f\"\\nProcessing {total} sentences with {max_concurrent} parallel workers...\")\n",
    "        \n",
    "#         # Process with progress\n",
    "#         for coro in asyncio.as_completed(tasks):\n",
    "#             sid, kpis = await coro\n",
    "#             results[sid] = kpis\n",
    "#             completed += 1\n",
    "            \n",
    "#             # Progress bar\n",
    "#             bar_length = 40\n",
    "#             filled = int(bar_length * completed / total)\n",
    "#             bar = \"█\" * filled + \"░\" * (bar_length - filled)\n",
    "            \n",
    "#             elapsed = time.time() - start_time\n",
    "#             rate = completed / elapsed if elapsed > 0 else 0\n",
    "            \n",
    "#             print(f\"\\r[{bar}] {completed}/{total} ({completed/total*100:.0f}%) | \"\n",
    "#                   f\"{rate:.1f} sent/s\", end=\"\", flush=True)\n",
    "        \n",
    "#         print()  # New line after progress bar\n",
    "#         return results\n",
    "\n",
    "# # =============================================================================\n",
    "# # SYNCHRONOUS FALLBACK (for debugging)\n",
    "# # =============================================================================\n",
    "\n",
    "# def extract_kpis_sync(text: str, sentence_id: str) -> List[Dict]:\n",
    "#     \"\"\"Synchronous extraction for testing\"\"\"\n",
    "#     prompt = f\"\"\"Extract financial numbers from: \"{text}\"\n",
    "# Output JSON: [{{\"category\":\"type\",\"value\":number,\"unit\":\"unit\"}}]\"\"\"\n",
    "    \n",
    "#     payload = {\n",
    "#         \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "#         \"temperature\": 0.1,\n",
    "#         \"max_tokens\": 150,\n",
    "#     }\n",
    "    \n",
    "#     try:\n",
    "#         response = requests.post(f\"{V1_URL}/chat/completions\", json=payload, timeout=30)\n",
    "#         if response.status_code == 200:\n",
    "#             content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "#             cleaned = clean_json_response(content)\n",
    "#             data = json.loads(cleaned) if cleaned and cleaned != \"[]\" else []\n",
    "#             return data if isinstance(data, list) else []\n",
    "#     except Exception as e:\n",
    "#         print(f\"Sync extraction error: {e}\")\n",
    "#     return []\n",
    "\n",
    "# # =============================================================================\n",
    "# # MAIN EXECUTION\n",
    "# # =============================================================================\n",
    "\n",
    "# def run_async_in_jupyter(coro):\n",
    "#     \"\"\"Helper to run async code in Jupyter/IPython\"\"\"\n",
    "#     try:\n",
    "#         # Try to get existing loop\n",
    "#         loop = asyncio.get_running_loop()\n",
    "#         # Create task and run\n",
    "#         import nest_asyncio\n",
    "#         nest_asyncio.apply()\n",
    "#         return asyncio.run(coro)\n",
    "#     except RuntimeError:\n",
    "#         # No loop running, use asyncio.run\n",
    "#         return asyncio.run(coro)\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "#     # Test sentences\n",
    "#     test_sentences = [\n",
    "#         \"For 2018, we estimate that mobile advertising revenue represented approximately 92% of total advertising revenue, as compared with approximately 88% in 2017.\",\n",
    "#         \"Realization of deferred tax assets associated with net operating loss and credit carryforwards is dependent upon generating sufficient taxable income prior to their expiration in the appropriate tax jurisdiction.\",\n",
    "#         \"A reduction of 85 million BOE was recorded in Canada, primarily from commodity price effects at Kaybob Duvernay.\",\n",
    "#         \"2018 compared to 2017 The Other segment reported net income of $14 million for the year ended December 31, 2018, compared to net loss of $71 million for the year ended December 31, 2017.\",\n",
    "#         \"Future policy benefits for individual life insurance and annuity policies consider crediting rates ranging from 2 1/2% to 6% for life insurance and 2% to 9 1/2% for annuities.\",\n",
    "#         \"The following table presents restructuring activity for the years ended June 30, 2019 and 2018: Separation Costs Employee separation charges for the years ended June 30, 2019 and 2018 relate to severance packages for approximately 1,810 and 2,720 employees, respectively.\",\n",
    "#         \"In May 2017, we issued $750.0 million of 2.35 percent fixed-rate notes due in May 2022, $750.0 million of 3.10 percent fixed-rate notes due in May 2027, and $750.0 million of 3.95 percent fixed-rate notes due in May 2047, with interest to be paid semi-annually.\"\n",
    "#     ]\n",
    "    \n",
    "#     print(\"=\"*70)\n",
    "#     print(\"Financial KPI Extractor - FIXED VERSION\")\n",
    "#     print(\"Model: Qwen2.5-7B-Instruct Q5_K_M\")\n",
    "#     print(\"=\"*70)\n",
    "    \n",
    "#     server_process = None\n",
    "    \n",
    "#     try:\n",
    "#         # Start server\n",
    "#         server_process = start_llama_server(MODEL_PATH)\n",
    "        \n",
    "#         # Give it a moment to stabilize\n",
    "#         time.sleep(2)\n",
    "        \n",
    "#         # Test with synchronous first\n",
    "#         print(\"\\n\" + \"=\"*70)\n",
    "#         print(\"Testing with synchronous extraction first...\")\n",
    "#         print(\"=\"*70)\n",
    "        \n",
    "#         test_sid = \"S001\"\n",
    "#         test_text = test_sentences[0]\n",
    "#         print(f\"\\nTest sentence: {test_text[:80]}...\")\n",
    "        \n",
    "#         test_result = extract_kpis_sync(test_text, test_sid)\n",
    "#         if test_result:\n",
    "#             print(f\"✓ Sync test successful: {test_result}\")\n",
    "#         else:\n",
    "#             print(\"⚠ Sync test returned no results\")\n",
    "        \n",
    "#         # Prepare data for async\n",
    "#         test_data = [(f\"S{i:03d}\", sent) for i, sent in enumerate(test_sentences, 1)]\n",
    "        \n",
    "#         print(\"\\n\" + \"=\"*70)\n",
    "#         print(\"Running async batch extraction...\")\n",
    "#         print(\"=\"*70)\n",
    "        \n",
    "#         # Run async with proper handling for Jupyter\n",
    "#         try:\n",
    "#             # Check if we're in Jupyter/IPython\n",
    "#             get_ipython()  # This will raise NameError if not in IPython\n",
    "#             print(\"Detected Jupyter/IPython environment\")\n",
    "            \n",
    "#             # Use nest_asyncio approach\n",
    "#             import nest_asyncio\n",
    "#             nest_asyncio.apply()\n",
    "#             results = asyncio.run(batch_extract_kpis(test_data, max_concurrent=MAX_CONCURRENT))\n",
    "            \n",
    "#         except NameError:\n",
    "#             # Not in Jupyter, use normal asyncio\n",
    "#             print(\"Running in standard Python environment\")\n",
    "#             results = asyncio.run(batch_extract_kpis(test_data, max_concurrent=MAX_CONCURRENT))\n",
    "        \n",
    "#         # Display results\n",
    "#         print(\"\\n\" + \"=\"*70)\n",
    "#         print(\"EXTRACTION RESULTS\")\n",
    "#         print(\"=\"*70)\n",
    "        \n",
    "#         total_kpis = 0\n",
    "#         sentences_with_kpis = 0\n",
    "        \n",
    "#         for i, (sid, sent) in enumerate(test_data, 1):\n",
    "#             kpis = results.get(sid, [])\n",
    "            \n",
    "#             print(f\"\\n[{sid}] Sentence {i}:\")\n",
    "#             print(f\"Text: {sent[:100]}...\")\n",
    "            \n",
    "#             if kpis:\n",
    "#                 sentences_with_kpis += 1\n",
    "#                 total_kpis += len(kpis)\n",
    "#                 for kpi in kpis:\n",
    "#                     # Format KPI nicely\n",
    "#                     cat = kpi.get('category', 'unknown')\n",
    "#                     val = kpi.get('value', 'N/A')\n",
    "#                     unit = kpi.get('unit', '')\n",
    "#                     year = kpi.get('year', '')\n",
    "#                     year_str = f\" ({year})\" if year else \"\"\n",
    "#                     print(f\"  ✓ {cat}: {val} {unit}{year_str}\")\n",
    "#             else:\n",
    "#                 print(\"  ✗ No KPIs extracted\")\n",
    "        \n",
    "#         # Summary\n",
    "#         print(\"\\n\" + \"=\"*70)\n",
    "#         print(\"SUMMARY\")\n",
    "#         print(\"=\"*70)\n",
    "#         print(f\"Sentences processed: {len(test_data)}\")\n",
    "#         print(f\"Sentences with KPIs: {sentences_with_kpis}/{len(test_data)} ({sentences_with_kpis/len(test_data)*100:.0f}%)\")\n",
    "#         print(f\"Total KPIs extracted: {total_kpis}\")\n",
    "#         if len(test_data) > 0:\n",
    "#             print(f\"Average KPIs/sentence: {total_kpis/len(test_data):.1f}\")\n",
    "        \n",
    "#     except KeyboardInterrupt:\n",
    "#         print(\"\\n\\n⚠ Interrupted by user\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"\\n❌ Error: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "        \n",
    "#     finally:\n",
    "#         if server_process:\n",
    "#             stop_server(server_process)\n",
    "    \n",
    "#     print(\"\\n\" + \"=\"*70)\n",
    "#     print(\"Session complete\")\n",
    "#     print(\"=\"*70)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1dc5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c8445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f47077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8612e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd460809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87417096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finrag_mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
